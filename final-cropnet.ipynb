{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9594770,"sourceType":"datasetVersion","datasetId":5852641}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"papermill":{"default_parameters":{},"duration":23501.210571,"end_time":"2024-10-24T23:01:44.840393","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-10-24T16:30:03.629822","version":"2.6.0"}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"1e0cb19d","cell_type":"code","source":"!pip install -q einops","metadata":{"papermill":{"duration":12.907333,"end_time":"2024-10-24T16:30:19.322585","exception":false,"start_time":"2024-10-24T16:30:06.415252","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"14251e1e","cell_type":"markdown","source":"## IMPORT LIBS","metadata":{"papermill":{"duration":0.006475,"end_time":"2024-10-24T16:30:19.336130","exception":false,"start_time":"2024-10-24T16:30:19.329655","status":"completed"},"tags":[]}},{"id":"01993e66","cell_type":"code","source":"import os\nimport numpy as np\nimport random\nimport torch\nimport torch.optim as optim\nfrom torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\nfrom torch.amp import autocast\nfrom torch.utils.data import Dataset,DataLoader\nimport torch.nn as nn\nimport torchvision.models as models\nfrom tqdm import tqdm\nimport gc\nimport pandas as pd\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import OneHotEncoder\nfrom einops import rearrange\nimport h5py\nfrom sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\nfrom scipy.stats import pearsonr\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nfrom typing import List, Tuple\nfrom datetime import datetime, timedelta\nfrom pprint import pprint\nimport json\nimport math","metadata":{"papermill":{"duration":7.096781,"end_time":"2024-10-24T16:30:26.440077","exception":false,"start_time":"2024-10-24T16:30:19.343296","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"4436a76f","cell_type":"markdown","source":"## REPRODUCTIVITY","metadata":{"papermill":{"duration":0.006464,"end_time":"2024-10-24T16:30:26.454938","exception":false,"start_time":"2024-10-24T16:30:26.448474","status":"completed"},"tags":[]}},{"id":"a9255d4b","cell_type":"code","source":"# Set environment variable\nos.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n\nglobal_seed = 0\n\nrandom.seed(global_seed)\nnp.random.seed(global_seed)\n\ntorch.manual_seed(global_seed)\ntorch.use_deterministic_algorithms(True)","metadata":{"papermill":{"duration":0.020552,"end_time":"2024-10-24T16:30:26.482026","exception":false,"start_time":"2024-10-24T16:30:26.461474","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"d122b57f","cell_type":"code","source":"def make_config(years: List[int], state: str, state_ansi: str, fips: str, crop_type: str, grow_season: List[int]):\n\n    config = {\n        \"FIPS\": fips,\n        \"years\": years,\n        \"state\": state.upper(),\n        \"crop_type\": crop_type,\n        \"data\": {\n            \"HRRR\": {\n                \"short_term\": []\n            },\n            \"USDA\": [],\n            \"sentinel\": []\n        }\n    }\n    \n    for year in years:\n        # HRRR data\n        hrrr_files = [\n            f\"HRRR/{year}/{state.upper()}/HRRR_{state_ansi}_{state.upper()}_{year}-{month:02d}.csv\"\n            for month in range(grow_season[0], grow_season[1] + 1)\n        ]\n        config[\"data\"][\"HRRR\"][\"short_term\"].append(hrrr_files)\n        \n        # USDA data\n        if crop_type==\"Soybeans\":\n            config[\"data\"][\"USDA\"].append(f\"USDA/{crop_type}/{year}/USDA_Soybean_County_{year}.csv\")\n        else:\n            config[\"data\"][\"USDA\"].append(f\"USDA/{crop_type}/{year}/USDA_{crop_type}_County_{year}.csv\")\n        \n        # Sentinel data\n        quarters = [\n            (f\"{year}-01-01\", f\"{year}-03-31\"),\n            (f\"{year}-04-01\", f\"{year}-06-30\"),\n            (f\"{year}-07-01\", f\"{year}-09-30\"),\n            (f\"{year}-10-01\", f\"{year}-12-31\")\n        ]\n        \n        sentinel_files = []\n        for start, end in quarters:\n            quarter_start = datetime.strptime(start, \"%Y-%m-%d\")\n            quarter_end = datetime.strptime(end, \"%Y-%m-%d\")\n            if (grow_season[0] <= quarter_start.month <= grow_season[1]) or \\\n               (grow_season[0] <= quarter_end.month <= grow_season[1]):\n                sentinel_files.append(f\"AG/{state.upper()}/{year}/Agriculture_{state_ansi}_{state.upper()}_{start}_{end}.h5\")\n        \n        config[\"data\"][\"sentinel\"].append(sentinel_files)\n    \n    return config\n\n# Train\nyears = list(range(2018,2022))\nstate = \"AL\"\nstate_ansi = \"01\"\nfips = ['01003', '01015', '01019', '01031', '01039', '01045', '01047', '01053', '01061', \n        '01067', '01069', '01077', '01079', '01083', '01089', '01097', '01099', '01117'] \n\ncrop_type = \"Cotton\"\ngrow_season = [4, 9]  # April to September\n\ntrain_config = make_config(years, state, state_ansi, fips, crop_type, grow_season)\nwith open('train_config.json', 'w') as file:\n    json.dump(train_config, file)\nprint(\"Train config\")\npprint(train_config)\n\n# Test\nyears = [2022]\ntest_config = make_config(years,  state, state_ansi, fips, crop_type, grow_season)\nwith open('test_config.json', 'w') as file:\n    json.dump(test_config, file)\nprint(\"Test config\")\npprint(test_config)","metadata":{"jupyter":{"source_hidden":true},"papermill":{"duration":0.030242,"end_time":"2024-10-24T16:30:26.518983","exception":false,"start_time":"2024-10-24T16:30:26.488741","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"676d4d57","cell_type":"markdown","source":"## DATA LOADER","metadata":{"papermill":{"duration":0.006513,"end_time":"2024-10-24T16:30:26.532477","exception":false,"start_time":"2024-10-24T16:30:26.525964","status":"completed"},"tags":[]}},{"id":"6c1e11be","cell_type":"code","source":"class Sentinel2Imagery(Dataset):\n    def __init__(self, base_dir, config_file, transform=None):\n        self.transform = transform\n        self.base_dir = base_dir\n        \n        with open(config_file, 'r') as f:\n            obj = json.load(f)\n        \n        self.fips_codes = obj[\"FIPS\"]\n        self.years = obj[\"years\"]\n        self.file_paths = obj[\"data\"][\"sentinel\"]\n    \n    def __len__(self):\n        return len(self.fips_codes) * len(self.years)\n\n    def __getitem__(self, index):\n        fips_index = index // len(self.years)\n        year_index = index % len(self.years)\n        \n        fips_code = self.fips_codes[fips_index]\n        year = self.years[year_index]\n        file_paths = self.file_paths[year_index]\n        \n        temporal_list = []\n        for file_path in file_paths:\n            with h5py.File(os.path.join(self.base_dir, file_path), 'r') as hf:\n                groups = hf[fips_code]\n                for d in groups.keys():\n                    grids = groups[d][\"data\"]\n                    grids = torch.from_numpy(np.asarray(grids))\n                    temporal_list.append(grids)\n                hf.close()\n        x = torch.stack(temporal_list)\n        x = x.to(torch.float32)\n        x = rearrange(x, 't g h w c -> t g c h w')\n        if self.transform:\n            t, g, _, _, _ = x.shape\n            x = rearrange(x, 't g c h w -> (t g) c h w')\n            x = self.transform(x)\n            x = rearrange(x, '(t g) c h w -> t g c h w', t=t, g=g)\n        return x, fips_code, year\n\nclass HRRRComputedDataset(Dataset):\n    def __init__(self, base_dir, config_file, column_names=None):\n        self.base_dir = base_dir\n        self.day_range = [i + 1 for i in range(28)]\n        \n        with open(config_file, 'r') as f:\n            obj = json.load(f)\n        \n        self.fips_codes = obj[\"FIPS\"]\n        self.years = obj[\"years\"]\n        self.short_term_file_path = obj[\"data\"][\"HRRR\"][\"short_term\"]\n        \n        if column_names:\n            self.column_names = column_names\n        else:\n            self.column_names = [\n                'Avg Temperature (K)', 'Max Temperature (K)', 'Min Temperature (K)',\n                'Precipitation (kg m**-2)', 'Relative Humidity (%)', 'Wind Gust (m s**-1)',\n                'Wind Speed (m s**-1)', 'Downward Shortwave Radiation Flux (W m**-2)',\n                'Vapor Pressure Deficit (kPa)'\n            ]\n\n    def __len__(self):\n        return len(self.fips_codes) * len(self.years)\n\n    def __getitem__(self, index):\n        fips_index = index // len(self.years)\n        year_index = index % len(self.years)\n        \n        fips_code = self.fips_codes[fips_index]\n        year = self.years[year_index]\n        short_term_file_paths = self.short_term_file_path[year_index]\n        x_short = self.get_short_term_val(fips_code, short_term_file_paths)\n        x_short = x_short.to(torch.float32)\n        return x_short, fips_code, year\n\n    def get_short_term_val(self, fips_code, file_paths):\n        df_list = []\n        for file_path in file_paths:\n            tmp_df = pd.read_csv(os.path.join(self.base_dir, file_path))\n            df_list.append(tmp_df)\n\n        df = pd.concat(df_list, ignore_index=True)\n        df[\"FIPS Code\"] = df[\"FIPS Code\"].astype(str).str.zfill(5)\n        df = df[(df[\"FIPS Code\"] == fips_code) & (df[\"Daily/Monthly\"] == \"Daily\")]\n        df.columns = df.columns.str.strip()\n\n        group_month = df.groupby(['Month'])\n\n        temporal_list = []\n        for month, df_month in group_month:\n            group_grid = df_month.groupby(['Grid Index'])\n\n            time_series = []\n            for grid, df_grid in group_grid:\n                df_grid = df_grid.sort_values(by=['Day'], ascending=[True], na_position='first')\n                df_grid = df_grid[df_grid.Day.isin(self.day_range)]\n                df_grid = df_grid[self.column_names]\n                val = self.signed_log_transform(torch.from_numpy(df_grid.values))\n                time_series.append(val)\n\n            temporal_list.append(torch.stack(time_series))\n\n        x_short = torch.stack(temporal_list)\n        x_short = rearrange(x_short, 'm g d p -> m d g p')\n        return x_short\n\n    def signed_log_transform(self, data):\n        epsilon = 1e-9  # small constant to avoid log(0)\n        return torch.sign(data) * torch.log10(torch.abs(data) + epsilon)\n\nclass USDACropDataset(Dataset):\n    def __init__(self, base_dir, config_file, crop_type):\n        self.base_dir = base_dir\n        self.crop_type = crop_type\n        \n        with open(config_file, 'r') as f:\n            obj = json.load(f)\n        \n        self.fips_codes = obj[\"FIPS\"]\n        self.years = obj[\"years\"]\n        self.file_paths = obj[\"data\"][\"USDA\"]\n\n        if crop_type == \"Cotton\":\n            self.column_names = ['PRODUCTION, MEASURED IN 480 LB BALES', 'YIELD, MEASURED IN LB / ACRE']\n        else:\n            self.column_names = ['PRODUCTION, MEASURED IN BU', 'YIELD, MEASURED IN BU / ACRE']\n\n        \n    def __len__(self):\n        return len(self.fips_codes) * len(self.years)\n    def get_num_classes(self):\n        return len(self.fips_encoder.classes_)\n    def __getitem__(self, index):\n        fips_index = index // len(self.years)\n        year_index = index % len(self.years)\n        \n        fips_code = self.fips_codes[fips_index]\n        year = self.years[year_index]\n        file_path = self.file_paths[year_index]\n        df = pd.read_csv(os.path.join(self.base_dir, file_path))\n\n        df['state_ansi'] = df['state_ansi'].astype(str).str.zfill(2)\n        df['county_ansi'] = df['county_ansi'].astype(str).str.zfill(3)\n\n        df = df[(df[\"state_ansi\"] == fips_code[:2]) & (df[\"county_ansi\"] == fips_code[-3:])]\n\n        df = df[self.column_names]\n        x = torch.from_numpy(df.values)\n        x = x.to(torch.float32)\n        x = torch.log(torch.flatten(x, start_dim=0))\n        return x, fips_code, year","metadata":{"papermill":{"duration":0.039172,"end_time":"2024-10-24T16:30:26.578437","exception":false,"start_time":"2024-10-24T16:30:26.539265","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"d832e3a9","cell_type":"markdown","source":"## MODAL ARCHITECTURE","metadata":{"papermill":{"duration":0.006518,"end_time":"2024-10-24T16:30:26.591757","exception":false,"start_time":"2024-10-24T16:30:26.585239","status":"completed"},"tags":[]}},{"id":"76d021ef","cell_type":"code","source":"class SatelliteEncoder(nn.Module):\n    def __init__(self, output_dim=128, max_temporal_len=50):\n        super().__init__()\n        # Base ResNet feature extractor (without final layers)\n        resnet = models.resnet18(pretrained=True)\n        self.features = nn.Sequential(*list(resnet.children())[:-2])\n        \n        # Temporal modeling components\n        self.temporal_conv = nn.Sequential(\n            nn.Conv3d(512, 256, kernel_size=(3, 3, 3), padding=(1, 1, 1)),\n            nn.BatchNorm3d(256),\n            nn.LeakyReLU(0.1),\n            nn.Conv3d(256, 128, kernel_size=(3, 3, 3), padding=(1, 1, 1)),\n            nn.BatchNorm3d(128),\n            nn.LeakyReLU(0.1)\n        )\n        \n        # Temporal attention mechanism\n        self.temporal_attention = nn.MultiheadAttention(\n            embed_dim=128,\n            num_heads=4,\n            batch_first=True\n        )\n        \n        # Sinusoidal position encoding\n        self.register_buffer(\n            \"pos_encoder\", \n            self._get_position_encoding(max_temporal_len, 128)\n        )\n        \n        self.fc = nn.Linear(128, output_dim)\n        \n        # Layer normalization for attention\n        self.norm1 = nn.LayerNorm(128)\n        self.norm2 = nn.LayerNorm(128)\n        \n    def _get_position_encoding(self, max_len, d_model):\n        # Create position encoding matrix\n        pe = torch.zeros(max_len, d_model)\n        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n        \n        pe[:, 0::2] = torch.sin(position * div_term)\n        pe[:, 1::2] = torch.cos(position * div_term[:d_model//2])\n        \n        return pe.unsqueeze(0)  # [1, max_len, d_model]\n        \n    def forward(self, x):\n        # x shape: [batch, t, g, c, h, w]\n        batch, t, g, c, h, w = x.shape\n        \n        # Process each temporal step through ResNet\n        x = x.view(batch * t * g, c, h, w)\n        x = self.features(x)  # [batch*t*g, 512, h', w']\n        \n        # Reshape for temporal processing\n        _, ch, h_out, w_out = x.shape\n        x = x.view(batch * g, t, ch, h_out, w_out)\n        x = x.permute(0, 2, 1, 3, 4)  # [batch*g, ch, t, h', w']\n        \n        # Apply 3D temporal convolutions\n        x = self.temporal_conv(x)  # [batch*g, 128, t, h', w']\n        \n        # Global spatial-temporal pooling\n        x = x.mean(dim=(-1, -2))  # [batch*g, 128, t]\n        x = x.permute(0, 2, 1)  # [batch*g, t, 128]\n        \n        # Add positional encoding for the actual sequence length\n        pos_enc = self.pos_encoder[:, :t, :]\n        x = x + pos_enc\n        x = self.norm1(x)\n        \n        # Use attention masking for variable length\n        attn_mask = None\n        attn_out, _ = self.temporal_attention(x, x, x, attn_mask=attn_mask)\n        x = self.norm2(x + attn_out)  # Residual connection\n        \n        # Final temporal pooling and feature projection\n        x = x.mean(dim=1)  # Average over temporal dimension\n        x = self.fc(x)\n        \n        # Reshape back to [batch, g, output_dim]\n        x = x.view(batch, g, -1)\n        \n        return x\n\n\nclass WeatherEncoder(nn.Module):\n    def __init__(self, input_dim=9):\n        super().__init__()\n        self.lstm = nn.LSTM(input_dim, 64, num_layers=2, batch_first=True)\n        self.fc = nn.Linear(64, 32)\n    \n    def forward(self, x):\n        # x shape: [batch, m, d, g, p]\n        batch, m, d, g, p = x.shape\n        x = rearrange(x, 'b m d g p -> (b g) (m d) p')\n        x, _ = self.lstm(x)\n        x = self.fc(x[:, -1, :])  # Take the last output\n        return rearrange(x, '(b g) c -> b g c', b=batch, g=g)  # Output: [batch, g, 32]\n\nclass CropYieldModel(nn.Module):\n    def __init__(self, num_fips):\n        super().__init__()\n        self.satellite_encoder = SatelliteEncoder()\n        self.weather_encoder = WeatherEncoder()\n        \n        # Fusion module for combining satellite and weather features\n        self.fusion_layer = nn.Sequential(\n            nn.Linear(128 + 32, 64),\n            nn.LayerNorm(64),\n            nn.LeakyReLU(0.1),\n            nn.Dropout(p=0.2),\n            nn.Linear(64, 32),\n            nn.LayerNorm(32),\n            nn.LeakyReLU(0.1),\n        )\n        \n        # Grid feature aggregation using weighted pooling\n        self.grid_weights = nn.Sequential(\n            nn.Linear(32, 16),\n            nn.LeakyReLU(0.1),\n            nn.Linear(16, 1),\n            nn.Softmax(dim=1)\n        )\n        \n        # Final prediction layers with FIPS embedding\n        self.output_layer = nn.Sequential(\n            nn.Linear(32 + num_fips, 32),\n            nn.LayerNorm(32),\n            nn.LeakyReLU(0.1),\n            nn.Dropout(0.2),\n            nn.Linear(32, 16),\n            nn.LeakyReLU(0.1),\n            nn.Linear(16, 2)  # 2 outputs: production and yield\n        )\n        \n    def forward(self, satellite, weather, fips):\n        # Get encoded features\n        sat_features = self.satellite_encoder(satellite)  # [batch, g, 128]\n        weather_features = self.weather_encoder(weather)  # [batch, g, 32]\n        \n        # Combine satellite and weather features for each grid\n        combined_features = torch.cat([sat_features, weather_features], dim=-1)  # [batch, g, 160]\n        fused_grid_features = self.fusion_layer(combined_features)  # [batch, g, 32]\n        \n        # Calculate attention weights for each grid\n        grid_attention_weights = self.grid_weights(fused_grid_features)  # [batch, g, 1]\n        \n        # Apply weighted pooling over grids\n        county_features = torch.sum(\n            fused_grid_features * grid_attention_weights, \n            dim=1\n        )  # [batch, 32]\n        \n        # Concatenate with FIPS embedding and make final prediction\n        county_features = torch.cat([county_features, fips], dim=-1)  # [batch, 32 + num_fips]\n        output = self.output_layer(county_features)  # [batch, 2]\n        \n        return output","metadata":{"jupyter":{"source_hidden":true},"papermill":{"duration":0.035537,"end_time":"2024-10-24T16:30:26.634118","exception":false,"start_time":"2024-10-24T16:30:26.598581","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"3358ae95","cell_type":"markdown","source":"## TRAIN AND TEST","metadata":{"papermill":{"duration":0.006534,"end_time":"2024-10-24T16:30:26.647294","exception":false,"start_time":"2024-10-24T16:30:26.640760","status":"completed"},"tags":[]}},{"id":"adae40e1","cell_type":"code","source":"def train_model(model, train_data, epochs=100, patience=5, save_path=\"best_model.pth\"):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    print(f\"Using device: {device}\")\n    \n    model = model.to(device)\n\n    train_sentinel_loader, train_hrrr_loader, train_usda_loader = train_data\n    \n    criterion = nn.HuberLoss()\n    optimizer = optim.RMSprop(model.parameters(), lr=0.001, weight_decay=1e-5)\n    scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2)\n    \n    best_train_loss = float('inf')\n    counter = 0\n    train_losses = []\n\n    for epoch in range(epochs):\n        # Training\n        model.train()\n        train_running_loss = 0.0\n        for (sentinel, fips_code, year), (hrrr, _, _), (usda, _, _) in tqdm(zip(train_sentinel_loader, train_hrrr_loader, train_usda_loader), desc=f\"Epoch {epoch+1} Training\"):\n            gc.collect()\n            torch.cuda.empty_cache()\n            sentinel, hrrr, usda = sentinel.to(device), hrrr.to(device), usda.to(device)\n            fips_onehot = torch.tensor(fips_encoder.transform(np.array(fips_code).reshape(-1, 1)), dtype=torch.float32).to(device)      \n            optimizer.zero_grad()\n            with autocast(device_type=str(device)):\n                output = model(sentinel, hrrr, fips_onehot)\n                loss = criterion(output,usda)\n            loss.backward()\n#             torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n#             torch.autograd.set_detect_anomaly(True)\n            optimizer.step()\n            train_running_loss += loss.item()\n        \n        train_epoch_loss = train_running_loss / len(train_sentinel_loader)\n        train_losses.append(train_epoch_loss)\n    \n        scheduler.step()\n        \n        print(f\"Epoch {epoch+1} - Train Loss: {train_epoch_loss:.4f}\")\n        \n        if train_epoch_loss < best_train_loss:\n            best_train_loss = train_epoch_loss\n            torch.save(model.state_dict(), save_path)\n            counter = 0\n        else:\n            counter += 1\n            if counter >= patience:\n                print(\"Early stopping\")\n                break\n    return model\n\ndef evaluate_model(model, test_data):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model = model.to(device)\n    model.eval()\n    sentinel_loader, hrrr_loader, usda_loader = test_data\n    all_predictions = []\n    all_ground_truth = []\n\n    with torch.no_grad():\n        for (sentinel, fips_code, year), (hrrr, fips_code, year), (usda, fips_code, year) in zip(sentinel_loader, hrrr_loader, usda_loader):\n            sentinel, hrrr, usda = sentinel.to(device), hrrr.to(device), usda.to(device)\n            fips_onehot = torch.tensor(fips_encoder.transform(np.array(fips_code).reshape(-1, 1)), dtype=torch.float32).to(device)\n    \n            output = model(sentinel, hrrr, fips_onehot)\n        \n            all_predictions.append(output.cpu().numpy())\n            all_ground_truth.append(usda.cpu().numpy())\n        \n    all_predictions = np.concatenate(all_predictions, axis=0)\n    all_ground_truth = np.concatenate(all_ground_truth, axis=0)\n    print(all_predictions[:,0])\n    print(all_ground_truth[:,0])\n    print(all_predictions[:,1])\n    print(all_ground_truth[:,1])\n    results = {}\n    for i, metric_name in enumerate([\"Production\", \"Yield\"]):\n        y_true = torch.from_numpy(all_ground_truth[:, i])\n        y_pred = torch.from_numpy(all_predictions[:, i])\n        mae = torch.abs(y_true - y_pred).mean()\n        mse = ((y_pred - y_true) ** 2).mean()\n        rmse = torch.sqrt(mse)\n        mape = (torch.abs(y_true - y_pred) / torch.abs(y_true)).mean() * 100\n        smape = 100 * (torch.abs(y_true - y_pred) / ((torch.abs(y_true) + torch.abs(y_pred)) / 2)).mean()\n        max_error = torch.abs(y_true - y_pred).max()\n        corr = torch.corrcoef(torch.stack((y_pred, y_true)))\n        metrics = {\n            'MAE': round(mae.item(), 2),\n            'MSE': round(mse.item(), 2),\n            'RMSE': round(rmse.item(), 2),\n            'MAPE': round(mape.item(), 2),\n            'SMAPE': round(smape.item(), 2),\n            'Max Error': round(max_error.item(), 2),\n            'Correlation Coefficient': round(corr[0, 1].item(), 2)\n        }\n        results[metric_name] = metrics\n    return results","metadata":{"papermill":{"duration":0.031231,"end_time":"2024-10-24T16:30:26.685250","exception":false,"start_time":"2024-10-24T16:30:26.654019","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"3dd58bbd","cell_type":"markdown","source":"## RUN MODEL","metadata":{"papermill":{"duration":0.006494,"end_time":"2024-10-24T16:30:26.698363","exception":false,"start_time":"2024-10-24T16:30:26.691869","status":"completed"},"tags":[]}},{"id":"1fad05f7","cell_type":"markdown","source":"## Cotton","metadata":{"papermill":{"duration":0.00643,"end_time":"2024-10-24T16:30:26.711640","exception":false,"start_time":"2024-10-24T16:30:26.705210","status":"completed"},"tags":[]}},{"id":"80ba8753","cell_type":"code","source":"gc.collect()\ntorch.cuda.empty_cache()\nbase_dir = \"/kaggle/input/cropnetv2\"\ntrain_config = \"/kaggle/working/train_config.json\"\ntest_config = \"/kaggle/working/test_config.json\"\n\ntrain_sentinel_loader = DataLoader(Sentinel2Imagery(base_dir,train_config),batch_size = 1)\ntrain_hrrr_loader = DataLoader(HRRRComputedDataset(base_dir,train_config),batch_size = 1)\ntrain_usda_loader = DataLoader(USDACropDataset(base_dir,train_config,crop_type),batch_size = 1)\n    \ntest_sentinel_loader = DataLoader(Sentinel2Imagery(base_dir,test_config),batch_size = 1)\ntest_hrrr_loader = DataLoader(HRRRComputedDataset(base_dir,test_config),batch_size = 1)\ntest_usda_loader = DataLoader(USDACropDataset(base_dir,test_config,crop_type),batch_size = 1)\n\nwith open(train_config, 'r') as f:\n    obj = json.load(f)\n    fips_codes = sorted(obj[\"FIPS\"])\n    \nfips_encoder = OneHotEncoder(sparse_output=False)\nfips_encoder.fit(np.array(fips).reshape(-1, 1))\n\nmodel = CropYieldModel(len(fips_codes))\n\nmodel = train_model(model, (train_sentinel_loader, train_hrrr_loader, train_usda_loader),\n                    epochs=20, patience=5, save_path=\"best_model.pth\")\n\nresults = evaluate_model(model, (test_sentinel_loader, test_hrrr_loader, test_usda_loader))\nprint(crop_type)\npprint(results)","metadata":{"papermill":{"duration":1432.020434,"end_time":"2024-10-24T16:54:18.738837","exception":false,"start_time":"2024-10-24T16:30:26.718403","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"7c5b09c4","cell_type":"markdown","source":"## Corn","metadata":{"papermill":{"duration":0.047129,"end_time":"2024-10-24T16:54:18.833895","exception":false,"start_time":"2024-10-24T16:54:18.786766","status":"completed"},"tags":[]}},{"id":"4e5bbf97","cell_type":"code","source":"# Train\nyears = list(range(2018,2022))\nstate = \"IL\"\nstate_ansi = \"17\"\nfips = ['17007', '17011', '17015', '17017', '17019', '17021', '17025', '17027',  \n        '17037', '17049', '17053', '17055', '17057', '17059', '17061', '17063', '17073', \n        '17075', '17077', '17081', '17085', '17089', '17093', '17095', '17101', '17103', \n        '17105', '17107', '17113', '17115', '17117', '17119', '17121', '17123', '17133', \n        '17135', '17139', '17141', '17143', '17147', '17157', '17163', '17167', '17169', \n        '17173', '17175', '17177', '17179', '17189', '17193', '17195', '17201', '17203'] \ncrop_type = \"Corn\"\ngrow_season = [4, 9]  # April to September\n\ntrain_config = make_config(years, state, state_ansi, fips, crop_type, grow_season)\nwith open('train_config.json', 'w') as file:\n    json.dump(train_config, file)\nprint(\"Train config\")\npprint(train_config)\n\n# Test\nyears = [2022]\ntest_config = make_config(years,  state, state_ansi, fips, crop_type, grow_season)\nwith open('test_config.json', 'w') as file:\n    json.dump(test_config, file)\nprint(\"Test config\")\npprint(test_config)","metadata":{"papermill":{"duration":0.068213,"end_time":"2024-10-24T16:54:18.949737","exception":false,"start_time":"2024-10-24T16:54:18.881524","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"8a679978","cell_type":"code","source":"gc.collect()\ntorch.cuda.empty_cache()\nbase_dir = \"/kaggle/input/cropnetv2\"\ntrain_config = \"/kaggle/working/train_config.json\"\ntest_config = \"/kaggle/working/test_config.json\"\n\ntrain_sentinel_loader = DataLoader(Sentinel2Imagery(base_dir,train_config),batch_size = 1)\ntrain_hrrr_loader = DataLoader(HRRRComputedDataset(base_dir,train_config),batch_size = 1)\ntrain_usda_loader = DataLoader(USDACropDataset(base_dir,train_config,crop_type),batch_size = 1)\n    \ntest_sentinel_loader = DataLoader(Sentinel2Imagery(base_dir,test_config),batch_size = 1)\ntest_hrrr_loader = DataLoader(HRRRComputedDataset(base_dir,test_config),batch_size = 1)\ntest_usda_loader = DataLoader(USDACropDataset(base_dir,test_config,crop_type),batch_size = 1)\n\nwith open(train_config, 'r') as f:\n    obj = json.load(f)\n    fips_codes = sorted(obj[\"FIPS\"])\n    \nfips_encoder = OneHotEncoder(sparse_output=False)\nfips_encoder.fit(np.array(fips).reshape(-1, 1))\n\nmodel = CropYieldModel(len(fips_codes))\n\nmodel = train_model(model, (train_sentinel_loader, train_hrrr_loader, train_usda_loader),\n                    epochs=20, patience=5, save_path=\"best_model.pth\")\n\nresults = evaluate_model(model, (test_sentinel_loader, test_hrrr_loader, test_usda_loader))\nprint(crop_type)\npprint(results)","metadata":{"papermill":{"duration":6348.112756,"end_time":"2024-10-24T18:40:07.110693","exception":false,"start_time":"2024-10-24T16:54:18.997937","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"dd6ef27f","cell_type":"markdown","source":"## Soybeans","metadata":{"papermill":{"duration":0.272233,"end_time":"2024-10-24T18:40:07.645718","exception":false,"start_time":"2024-10-24T18:40:07.373485","status":"completed"},"tags":[]}},{"id":"b32887ec","cell_type":"code","source":"# Train\nyears = list(range(2018,2022))\nstate = \"IL\"\nstate_ansi = \"17\"\nfips = ['17005', '17007', '17009', '17011', '17015', '17019', '17025', '17027', '17037', \n        '17045', '17049', '17053', '17055', '17057', '17059', '17063', '17073', '17075', '17077', \n        '17081', '17089', '17091', '17095', '17101', '17103', '17105', '17113', '17115', '17117', \n        '17119', '17121', '17129', '17133', '17139', '17141', '17143', '17145', '17153', '17157', \n        '17163', '17167', '17173', '17177', '17179', '17189', '17193', '17197', '17201', '17203']\n\ncrop_type = \"Soybeans\"\ngrow_season = [4, 9]  # April to September\n\ntrain_config = make_config(years, state, state_ansi, fips, crop_type, grow_season)\nwith open('train_config.json', 'w') as file:\n    json.dump(train_config, file)\n\n# Test\nyears = [2022]\ntest_config = make_config(years,  state, state_ansi, fips, crop_type, grow_season)\nwith open('test_config.json', 'w') as file:\n    json.dump(test_config, file)","metadata":{"papermill":{"duration":0.27647,"end_time":"2024-10-24T18:40:08.198534","exception":false,"start_time":"2024-10-24T18:40:07.922064","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"c9c019ef","cell_type":"code","source":"gc.collect()\ntorch.cuda.empty_cache()\nbase_dir = \"/kaggle/input/cropnetv2\"\ntrain_config = \"/kaggle/working/train_config.json\"\ntest_config = \"/kaggle/working/test_config.json\"\n\ntrain_sentinel_loader = DataLoader(Sentinel2Imagery(base_dir,train_config),batch_size = 1)\ntrain_hrrr_loader = DataLoader(HRRRComputedDataset(base_dir,train_config),batch_size = 1)\ntrain_usda_loader = DataLoader(USDACropDataset(base_dir,train_config,crop_type),batch_size = 1)\n    \ntest_sentinel_loader = DataLoader(Sentinel2Imagery(base_dir,test_config),batch_size = 1)\ntest_hrrr_loader = DataLoader(HRRRComputedDataset(base_dir,test_config),batch_size = 1)\ntest_usda_loader = DataLoader(USDACropDataset(base_dir,test_config,crop_type),batch_size = 1)\n\nwith open(train_config, 'r') as f:\n    obj = json.load(f)\n    fips_codes = sorted(obj[\"FIPS\"])\n    \nfips_encoder = OneHotEncoder(sparse_output=False)\nfips_encoder.fit(np.array(fips).reshape(-1, 1))\n\nmodel = CropYieldModel(len(fips_codes))\n\nmodel = train_model(model, (train_sentinel_loader, train_hrrr_loader, train_usda_loader),\n                    epochs=20, patience=5, save_path=\"best_model.pth\")\n\nresults = evaluate_model(model, (test_sentinel_loader, test_hrrr_loader, test_usda_loader))\nprint(crop_type)\npprint(results)","metadata":{"papermill":{"duration":8970.280691,"end_time":"2024-10-24T21:09:38.743760","exception":false,"start_time":"2024-10-24T18:40:08.463069","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"0eb97ee2","cell_type":"markdown","source":"## Winter Wheat","metadata":{"papermill":{"duration":0.609479,"end_time":"2024-10-24T21:09:39.938646","exception":false,"start_time":"2024-10-24T21:09:39.329167","status":"completed"},"tags":[]}},{"id":"9e80f60f","cell_type":"code","source":"def make_config(years: List[int], state: str, state_ansi: str, fips: str, crop_type: str, grow_season: List[int]):\n    \"\"\"\n    Creates configuration for winter wheat data collection\n    grow_season: List containing [start_month, end_month] of the growing cycle\n                 For winter wheat, this spans across year boundary\n    \"\"\"\n    config = {\n        \"FIPS\": fips,\n        \"years\": years,\n        \"state\": state.upper(),\n        \"crop_type\": crop_type,\n        \"data\": {\n            \"HRRR\": {\n                \"short_term\": []\n            },\n            \"USDA\": [],\n            \"sentinel\": []\n        }\n    }\n   \n    for year in years:\n        # HRRR data - need to consider months from previous year's fall\n        hrrr_files = []\n        # Previous year's fall months (planting)\n        for month in range(9, 13):  # September to December\n            hrrr_files.append(f\"HRRR/{year-1}/{state.upper()}/HRRR_{state_ansi}_{state.upper()}_{year-1}-{month:02d}.csv\")\n        # Current year's winter and spring months (growing and harvest)\n        for month in range(1, 7):  # January to July\n            hrrr_files.append(f\"HRRR/{year}/{state.upper()}/HRRR_{state_ansi}_{state.upper()}_{year}-{month:02d}.csv\")\n        \n        config[\"data\"][\"HRRR\"][\"short_term\"].append(hrrr_files)\n       \n        # USDA data\n        config[\"data\"][\"USDA\"].append(f\"USDA/{crop_type}/{year}/USDA_WinterWheat_County_{year}.csv\")\n       \n        # Sentinel data - need to cover previous fall to current summer\n        quarters = [\n            # Previous year quarters\n            (f\"{year-1}-10-01\", f\"{year-1}-12-31\"),  # Q4 (planting)\n            # Current year quarters\n            (f\"{year}-01-01\", f\"{year}-03-31\"),      # Q1 (winter growth)\n            (f\"{year}-04-01\", f\"{year}-06-30\"),      # Q2 (spring growth)\n        ]\n       \n        sentinel_files = []\n        for start, end in quarters:\n            sentinel_files.append(f\"AG/{state.upper()}/{start[:4]}/Agriculture_{state_ansi}_{state.upper()}_{start}_{end}.h5\")\n       \n        config[\"data\"][\"sentinel\"].append(sentinel_files)\n   \n    return config\n\n# Train\nyears = list(range(2018, 2022))\nstate = \"IL\"\nstate_ansi = \"17\"\nfips = ['17011', '17013', '17023', '17025', '17027', '17037', '17047', '17049', '17067', \n        '17083', '17089', '17095', '17119', '17121', '17125', '17133', '17141', '17157', '17159', \n        '17163', '17173', '17177', '17179', '17189', '17201'] \ncrop_type = \"WinterWheat\"\ngrow_season = [9, 6]  # September to July (spanning across years)\n\ntrain_config = make_config(years, state, state_ansi, fips, crop_type, grow_season)\nwith open('train_config.json', 'w') as file:\n    json.dump(train_config, file)\n\n\n# Test\nyears = [2022]\ntest_config = make_config(years, state, state_ansi, fips, crop_type, grow_season)\nwith open('test_config.json', 'w') as file:\n    json.dump(test_config, file)","metadata":{"papermill":{"duration":0.59163,"end_time":"2024-10-24T21:09:41.093130","exception":false,"start_time":"2024-10-24T21:09:40.501500","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"b09c1c89","cell_type":"code","source":"gc.collect()\ntorch.cuda.empty_cache()\nbase_dir = \"/kaggle/input/cropnetv2\"\ntrain_config = \"/kaggle/working/train_config.json\"\ntest_config = \"/kaggle/working/test_config.json\"\n\ntrain_sentinel_loader = DataLoader(Sentinel2Imagery(base_dir,train_config),batch_size = 1)\ntrain_hrrr_loader = DataLoader(HRRRComputedDataset(base_dir,train_config),batch_size = 1)\ntrain_usda_loader = DataLoader(USDACropDataset(base_dir,train_config,crop_type),batch_size = 1)\n    \ntest_sentinel_loader = DataLoader(Sentinel2Imagery(base_dir,test_config),batch_size = 1)\ntest_hrrr_loader = DataLoader(HRRRComputedDataset(base_dir,test_config),batch_size = 1)\ntest_usda_loader = DataLoader(USDACropDataset(base_dir,test_config,crop_type),batch_size = 1)\n\nwith open(train_config, 'r') as f:\n    obj = json.load(f)\n    fips_codes = sorted(obj[\"FIPS\"])\n    \nfips_encoder = OneHotEncoder(sparse_output=False)\nfips_encoder.fit(np.array(fips).reshape(-1, 1))\n\nmodel = CropYieldModel(len(fips_codes))\n\nmodel = train_model(model, (train_sentinel_loader, train_hrrr_loader, train_usda_loader),\n                    epochs=20, patience=5, save_path=\"best_model.pth\")\n\nresults = evaluate_model(model, (test_sentinel_loader, test_hrrr_loader, test_usda_loader))\nprint(crop_type)\npprint(results)","metadata":{"papermill":{"duration":6720.881457,"end_time":"2024-10-24T23:01:42.596504","exception":false,"start_time":"2024-10-24T21:09:41.715047","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null}]}