{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e83265bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-25T06:08:28.419721Z",
     "iopub.status.busy": "2024-10-25T06:08:28.419292Z",
     "iopub.status.idle": "2024-10-25T06:08:41.337108Z",
     "shell.execute_reply": "2024-10-25T06:08:41.335875Z"
    },
    "papermill": {
     "duration": 12.928517,
     "end_time": "2024-10-25T06:08:41.339662",
     "exception": false,
     "start_time": "2024-10-25T06:08:28.411145",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q einops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3797000",
   "metadata": {
    "papermill": {
     "duration": 0.005977,
     "end_time": "2024-10-25T06:08:41.352225",
     "exception": false,
     "start_time": "2024-10-25T06:08:41.346248",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## IMPORT LIBS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a63d20ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-25T06:08:41.366594Z",
     "iopub.status.busy": "2024-10-25T06:08:41.365823Z",
     "iopub.status.idle": "2024-10-25T06:08:48.872168Z",
     "shell.execute_reply": "2024-10-25T06:08:48.871365Z"
    },
    "papermill": {
     "duration": 7.516203,
     "end_time": "2024-10-25T06:08:48.874548",
     "exception": false,
     "start_time": "2024-10-25T06:08:41.358345",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "from torch.amp import autocast\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from einops import rearrange\n",
    "import h5py\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from scipy.stats import pearsonr\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import List, Tuple\n",
    "from datetime import datetime, timedelta\n",
    "from pprint import pprint\n",
    "import json\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd717934",
   "metadata": {
    "papermill": {
     "duration": 0.005848,
     "end_time": "2024-10-25T06:08:48.886779",
     "exception": false,
     "start_time": "2024-10-25T06:08:48.880931",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## REPRODUCTIVITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99383d15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-25T06:08:48.901652Z",
     "iopub.status.busy": "2024-10-25T06:08:48.901106Z",
     "iopub.status.idle": "2024-10-25T06:08:48.911860Z",
     "shell.execute_reply": "2024-10-25T06:08:48.911161Z"
    },
    "papermill": {
     "duration": 0.019858,
     "end_time": "2024-10-25T06:08:48.913805",
     "exception": false,
     "start_time": "2024-10-25T06:08:48.893947",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set environment variable\n",
    "os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
    "\n",
    "global_seed = 0\n",
    "\n",
    "random.seed(global_seed)\n",
    "np.random.seed(global_seed)\n",
    "\n",
    "torch.manual_seed(global_seed)\n",
    "torch.use_deterministic_algorithms(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "643136be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-25T06:08:48.927421Z",
     "iopub.status.busy": "2024-10-25T06:08:48.927043Z",
     "iopub.status.idle": "2024-10-25T06:08:48.942783Z",
     "shell.execute_reply": "2024-10-25T06:08:48.942024Z"
    },
    "papermill": {
     "duration": 0.024754,
     "end_time": "2024-10-25T06:08:48.944698",
     "exception": false,
     "start_time": "2024-10-25T06:08:48.919944",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_config(years: List[int], state: str, state_ansi: str, fips: str, crop_type: str, grow_season: List[int]):\n",
    "\n",
    "    config = {\n",
    "        \"FIPS\": fips,\n",
    "        \"years\": years,\n",
    "        \"state\": state.upper(),\n",
    "        \"crop_type\": crop_type,\n",
    "        \"data\": {\n",
    "            \"HRRR\": {\n",
    "                \"short_term\": []\n",
    "            },\n",
    "            \"USDA\": [],\n",
    "            \"sentinel\": []\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    for year in years:\n",
    "        # HRRR data\n",
    "        hrrr_files = [\n",
    "            f\"HRRR/{year}/{state.upper()}/HRRR_{state_ansi}_{state.upper()}_{year}-{month:02d}.csv\"\n",
    "            for month in range(grow_season[0], grow_season[1] + 1)\n",
    "        ]\n",
    "        config[\"data\"][\"HRRR\"][\"short_term\"].append(hrrr_files)\n",
    "        \n",
    "        # USDA data\n",
    "        if crop_type==\"Soybeans\":\n",
    "            config[\"data\"][\"USDA\"].append(f\"USDA/{crop_type}/{year}/USDA_Soybean_County_{year}.csv\")\n",
    "        else:\n",
    "            config[\"data\"][\"USDA\"].append(f\"USDA/{crop_type}/{year}/USDA_{crop_type}_County_{year}.csv\")\n",
    "        \n",
    "        # Sentinel data\n",
    "        quarters = [\n",
    "            (f\"{year}-01-01\", f\"{year}-03-31\"),\n",
    "            (f\"{year}-04-01\", f\"{year}-06-30\"),\n",
    "            (f\"{year}-07-01\", f\"{year}-09-30\"),\n",
    "            (f\"{year}-10-01\", f\"{year}-12-31\")\n",
    "        ]\n",
    "        \n",
    "        sentinel_files = []\n",
    "        for start, end in quarters:\n",
    "            quarter_start = datetime.strptime(start, \"%Y-%m-%d\")\n",
    "            quarter_end = datetime.strptime(end, \"%Y-%m-%d\")\n",
    "            if (grow_season[0] <= quarter_start.month <= grow_season[1]) or \\\n",
    "               (grow_season[0] <= quarter_end.month <= grow_season[1]):\n",
    "                sentinel_files.append(f\"AG/{state.upper()}/{year}/Agriculture_{state_ansi}_{state.upper()}_{start}_{end}.h5\")\n",
    "        \n",
    "        config[\"data\"][\"sentinel\"].append(sentinel_files)\n",
    "    \n",
    "    return config\n",
    "\n",
    "# Train\n",
    "years = list(range(2018,2022))\n",
    "state = \"AL\"\n",
    "state_ansi = \"01\"\n",
    "fips = ['01003', '01015', '01019', '01031', '01039', '01045', '01047', '01053', '01061', \n",
    "        '01067', '01069', '01077', '01079', '01083', '01089', '01097', '01099', '01117'] \n",
    "\n",
    "crop_type = \"Cotton\"\n",
    "grow_season = [4, 9]  # April to September\n",
    "\n",
    "train_config = make_config(years, state, state_ansi, fips, crop_type, grow_season)\n",
    "with open('train_config.json', 'w') as file:\n",
    "    json.dump(train_config, file)\n",
    "\n",
    "# Test\n",
    "years = [2022]\n",
    "test_config = make_config(years,  state, state_ansi, fips, crop_type, grow_season)\n",
    "with open('test_config.json', 'w') as file:\n",
    "    json.dump(test_config, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd38c47f",
   "metadata": {
    "papermill": {
     "duration": 0.005795,
     "end_time": "2024-10-25T06:08:48.956696",
     "exception": false,
     "start_time": "2024-10-25T06:08:48.950901",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## DATA LOADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6b2112d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-25T06:08:48.970695Z",
     "iopub.status.busy": "2024-10-25T06:08:48.970358Z",
     "iopub.status.idle": "2024-10-25T06:08:48.999267Z",
     "shell.execute_reply": "2024-10-25T06:08:48.998273Z"
    },
    "papermill": {
     "duration": 0.038487,
     "end_time": "2024-10-25T06:08:49.001273",
     "exception": false,
     "start_time": "2024-10-25T06:08:48.962786",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Sentinel2Imagery(Dataset):\n",
    "    def __init__(self, base_dir, config_file, transform=None):\n",
    "        self.transform = transform\n",
    "        self.base_dir = base_dir\n",
    "        \n",
    "        with open(config_file, 'r') as f:\n",
    "            obj = json.load(f)\n",
    "        \n",
    "        self.fips_codes = obj[\"FIPS\"]\n",
    "        self.years = obj[\"years\"]\n",
    "        self.file_paths = obj[\"data\"][\"sentinel\"]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.fips_codes) * len(self.years)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        fips_index = index // len(self.years)\n",
    "        year_index = index % len(self.years)\n",
    "        \n",
    "        fips_code = self.fips_codes[fips_index]\n",
    "        year = self.years[year_index]\n",
    "        file_paths = self.file_paths[year_index]\n",
    "        \n",
    "        temporal_list = []\n",
    "        for file_path in file_paths:\n",
    "            with h5py.File(os.path.join(self.base_dir, file_path), 'r') as hf:\n",
    "                groups = hf[fips_code]\n",
    "                for d in groups.keys():\n",
    "                    grids = groups[d][\"data\"]\n",
    "                    grids = torch.from_numpy(np.asarray(grids))\n",
    "                    temporal_list.append(grids)\n",
    "                hf.close()\n",
    "        x = torch.stack(temporal_list)\n",
    "        x = x.to(torch.float32)\n",
    "        x = rearrange(x, 't g h w c -> t g c h w')\n",
    "        if self.transform:\n",
    "            t, g, _, _, _ = x.shape\n",
    "            x = rearrange(x, 't g c h w -> (t g) c h w')\n",
    "            x = self.transform(x)\n",
    "            x = rearrange(x, '(t g) c h w -> t g c h w', t=t, g=g)\n",
    "        return x, fips_code, year\n",
    "\n",
    "class HRRRComputedDataset(Dataset):\n",
    "    def __init__(self, base_dir, config_file, column_names=None):\n",
    "        self.base_dir = base_dir\n",
    "        self.day_range = [i + 1 for i in range(28)]\n",
    "        \n",
    "        with open(config_file, 'r') as f:\n",
    "            obj = json.load(f)\n",
    "        \n",
    "        self.fips_codes = obj[\"FIPS\"]\n",
    "        self.years = obj[\"years\"]\n",
    "        self.short_term_file_path = obj[\"data\"][\"HRRR\"][\"short_term\"]\n",
    "        \n",
    "        if column_names:\n",
    "            self.column_names = column_names\n",
    "        else:\n",
    "            self.column_names = [\n",
    "                'Avg Temperature (K)', 'Max Temperature (K)', 'Min Temperature (K)',\n",
    "                'Precipitation (kg m**-2)', 'Relative Humidity (%)', 'Wind Gust (m s**-1)',\n",
    "                'Wind Speed (m s**-1)', 'Downward Shortwave Radiation Flux (W m**-2)',\n",
    "                'Vapor Pressure Deficit (kPa)'\n",
    "            ]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.fips_codes) * len(self.years)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        fips_index = index // len(self.years)\n",
    "        year_index = index % len(self.years)\n",
    "        \n",
    "        fips_code = self.fips_codes[fips_index]\n",
    "        year = self.years[year_index]\n",
    "        short_term_file_paths = self.short_term_file_path[year_index]\n",
    "        x_short = self.get_short_term_val(fips_code, short_term_file_paths)\n",
    "        x_short = x_short.to(torch.float32)\n",
    "        return x_short, fips_code, year\n",
    "\n",
    "    def get_short_term_val(self, fips_code, file_paths):\n",
    "        df_list = []\n",
    "        for file_path in file_paths:\n",
    "            tmp_df = pd.read_csv(os.path.join(self.base_dir, file_path))\n",
    "            df_list.append(tmp_df)\n",
    "\n",
    "        df = pd.concat(df_list, ignore_index=True)\n",
    "        df[\"FIPS Code\"] = df[\"FIPS Code\"].astype(str).str.zfill(5)\n",
    "        df = df[(df[\"FIPS Code\"] == fips_code) & (df[\"Daily/Monthly\"] == \"Daily\")]\n",
    "        df.columns = df.columns.str.strip()\n",
    "\n",
    "        group_month = df.groupby(['Month'])\n",
    "\n",
    "        temporal_list = []\n",
    "        for month, df_month in group_month:\n",
    "            group_grid = df_month.groupby(['Grid Index'])\n",
    "\n",
    "            time_series = []\n",
    "            for grid, df_grid in group_grid:\n",
    "                df_grid = df_grid.sort_values(by=['Day'], ascending=[True], na_position='first')\n",
    "                df_grid = df_grid[df_grid.Day.isin(self.day_range)]\n",
    "                df_grid = df_grid[self.column_names]\n",
    "                val = self.signed_log_transform(torch.from_numpy(df_grid.values))\n",
    "                time_series.append(val)\n",
    "\n",
    "            temporal_list.append(torch.stack(time_series))\n",
    "\n",
    "        x_short = torch.stack(temporal_list)\n",
    "        x_short = rearrange(x_short, 'm g d p -> m d g p')\n",
    "        return x_short\n",
    "\n",
    "    def signed_log_transform(self, data):\n",
    "        epsilon = 1e-9  # small constant to avoid log(0)\n",
    "        return torch.sign(data) * torch.log10(torch.abs(data) + epsilon)\n",
    "\n",
    "class USDACropDataset(Dataset):\n",
    "    def __init__(self, base_dir, config_file, crop_type):\n",
    "        self.base_dir = base_dir\n",
    "        self.crop_type = crop_type\n",
    "        \n",
    "        with open(config_file, 'r') as f:\n",
    "            obj = json.load(f)\n",
    "        \n",
    "        self.fips_codes = obj[\"FIPS\"]\n",
    "        self.years = obj[\"years\"]\n",
    "        self.file_paths = obj[\"data\"][\"USDA\"]\n",
    "\n",
    "        if crop_type == \"Cotton\":\n",
    "            self.column_names = ['PRODUCTION, MEASURED IN 480 LB BALES', 'YIELD, MEASURED IN LB / ACRE']\n",
    "        else:\n",
    "            self.column_names = ['PRODUCTION, MEASURED IN BU', 'YIELD, MEASURED IN BU / ACRE']\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.fips_codes) * len(self.years)\n",
    "    def get_num_classes(self):\n",
    "        return len(self.fips_encoder.classes_)\n",
    "    def __getitem__(self, index):\n",
    "        fips_index = index // len(self.years)\n",
    "        year_index = index % len(self.years)\n",
    "        \n",
    "        fips_code = self.fips_codes[fips_index]\n",
    "        year = self.years[year_index]\n",
    "        file_path = self.file_paths[year_index]\n",
    "        df = pd.read_csv(os.path.join(self.base_dir, file_path))\n",
    "\n",
    "        df['state_ansi'] = df['state_ansi'].astype(str).str.zfill(2)\n",
    "        df['county_ansi'] = df['county_ansi'].astype(str).str.zfill(3)\n",
    "\n",
    "        df = df[(df[\"state_ansi\"] == fips_code[:2]) & (df[\"county_ansi\"] == fips_code[-3:])]\n",
    "\n",
    "        df = df[self.column_names]\n",
    "        x = torch.from_numpy(df.values)\n",
    "        x = x.to(torch.float32)\n",
    "        x = torch.log(torch.flatten(x, start_dim=0))\n",
    "        return x, fips_code, year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb22664f",
   "metadata": {
    "papermill": {
     "duration": 0.00591,
     "end_time": "2024-10-25T06:08:49.013585",
     "exception": false,
     "start_time": "2024-10-25T06:08:49.007675",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## MODAL ARCHITECTURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9bcb9d1e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-25T06:08:49.027236Z",
     "iopub.status.busy": "2024-10-25T06:08:49.026872Z",
     "iopub.status.idle": "2024-10-25T06:08:49.044352Z",
     "shell.execute_reply": "2024-10-25T06:08:49.043469Z"
    },
    "papermill": {
     "duration": 0.026617,
     "end_time": "2024-10-25T06:08:49.046270",
     "exception": false,
     "start_time": "2024-10-25T06:08:49.019653",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from einops import rearrange\n",
    "\n",
    "class SpatialEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # CNN layers for spatial feature extraction\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)  \n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        # Global average pooling to handle variable spatial dimensions\n",
    "        self.gap = nn.AdaptiveAvgPool2d(1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x shape: [batch*t*g, c, h, w]\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.gap(x)  # [batch*t*g, 64, 1, 1]\n",
    "        return x.squeeze(-1).squeeze(-1)  # [batch*t*g, 64]\n",
    "\n",
    "class TemporalEncoder(nn.Module):\n",
    "    def __init__(self, input_size=64):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=128,\n",
    "            num_layers=2,\n",
    "            batch_first=True,\n",
    "            dropout=0.2\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x shape: [batch, t, g, features]\n",
    "        batch, t, g, features = x.shape\n",
    "        \n",
    "        # Combine batch and grid dimensions for LSTM\n",
    "        x = rearrange(x, 'b t g f -> (b g) t f')\n",
    "        \n",
    "        # Run through LSTM\n",
    "        output, (hidden, _) = self.lstm(x)\n",
    "        \n",
    "        # Take final hidden state\n",
    "        hidden = hidden[-1]  # [batch*g, hidden_size]\n",
    "        \n",
    "        # Reshape back to separate batch and grid dimensions\n",
    "        hidden = hidden.view(batch, g, -1)  # [batch, g, hidden_size]\n",
    "        \n",
    "        # Average across grids\n",
    "        hidden = torch.mean(hidden, dim=1)  # [batch, hidden_size]\n",
    "        \n",
    "        return hidden\n",
    "\n",
    "class CropYieldModel(nn.Module):\n",
    "    def __init__(self, num_fips):\n",
    "        super().__init__()\n",
    "        self.spatial_encoder = SpatialEncoder()\n",
    "        self.temporal_encoder = TemporalEncoder()\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(128 + num_fips, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(32, 2)\n",
    "        )\n",
    "\n",
    "        \n",
    "    def forward(self, x, fips_onehot):\n",
    "        # x shape: [batch, t, g, c, h, w]\n",
    "        batch, t, g, c, h, w = x.shape\n",
    "        \n",
    "        # Reshape for CNN\n",
    "        x = rearrange(x, 'b t g c h w -> (b t g) c h w')\n",
    "        \n",
    "        # Extract spatial features\n",
    "        x = self.spatial_encoder(x)  # [batch*t*g, 64]\n",
    "        \n",
    "        # Reshape for LSTM\n",
    "        x = x.view(batch, t, g, -1)  # [batch, t, g, 64]\n",
    "        \n",
    "        # Process temporal features\n",
    "        x = self.temporal_encoder(x)  # [batch, 128]\n",
    "        \n",
    "        # Concatenate with FIPS one-hot encoding\n",
    "        x = torch.cat([x, fips_onehot], dim=1)\n",
    "        \n",
    "        # Final prediction\n",
    "        \n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6509415c",
   "metadata": {
    "papermill": {
     "duration": 0.005844,
     "end_time": "2024-10-25T06:08:49.058534",
     "exception": false,
     "start_time": "2024-10-25T06:08:49.052690",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## TRAIN AND TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "644e0a90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-25T06:08:49.072721Z",
     "iopub.status.busy": "2024-10-25T06:08:49.072018Z",
     "iopub.status.idle": "2024-10-25T06:08:49.096535Z",
     "shell.execute_reply": "2024-10-25T06:08:49.095787Z"
    },
    "papermill": {
     "duration": 0.033853,
     "end_time": "2024-10-25T06:08:49.098610",
     "exception": false,
     "start_time": "2024-10-25T06:08:49.064757",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_data, epochs=100, patience=5, save_path=\"best_model.pth\"):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    model = model.to(device)\n",
    "\n",
    "    train_sentinel_loader, train_hrrr_loader, train_usda_loader = train_data\n",
    "    \n",
    "    criterion = nn.HuberLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "    scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2)\n",
    "    \n",
    "    best_train_loss = float('inf')\n",
    "    counter = 0\n",
    "    train_losses = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        train_running_loss = 0.0\n",
    "        for (sentinel, fips_code, year), (hrrr, _, _), (usda, _, _) in tqdm(zip(train_sentinel_loader, train_hrrr_loader, train_usda_loader), desc=f\"Epoch {epoch+1} Training\"):\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "            model.half()\n",
    "            sentinel, hrrr, usda = sentinel.to(device), hrrr.to(device), usda.to(device)\n",
    "            fips_onehot = torch.tensor(fips_encoder.transform(np.array(fips_code).reshape(-1, 1)), dtype=torch.float32).to(device)      \n",
    "            optimizer.zero_grad()\n",
    "            with autocast(device_type=str(device)):\n",
    "                output = model(sentinel, fips_onehot)\n",
    "                loss = criterion(output, usda)\n",
    "            \n",
    "            loss.backward()\n",
    "            model.float()\n",
    "#             torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "#             torch.autograd.set_detect_anomaly(True)\n",
    "            optimizer.step()\n",
    "            train_running_loss += loss.item()\n",
    "        \n",
    "        train_epoch_loss = train_running_loss / len(train_sentinel_loader)\n",
    "        train_losses.append(train_epoch_loss)\n",
    "    \n",
    "        scheduler.step()\n",
    "        \n",
    "        print(f\"Epoch {epoch+1} - Train Loss: {train_epoch_loss:.4f}\")\n",
    "        \n",
    "        if train_epoch_loss < best_train_loss:\n",
    "            best_train_loss = train_epoch_loss\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            counter = 0\n",
    "        else:\n",
    "            counter += 1\n",
    "            if counter >= patience:\n",
    "                print(\"Early stopping\")\n",
    "                break\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, test_data):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    sentinel_loader, hrrr_loader, usda_loader = test_data\n",
    "    all_predictions = []\n",
    "    all_ground_truth = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for (sentinel, fips_code, year), (hrrr, fips_code, year), (usda, fips_code, year) in zip(sentinel_loader, hrrr_loader, usda_loader):\n",
    "            sentinel, hrrr, usda = sentinel.to(device), hrrr.to(device), usda.to(device)\n",
    "            fips_onehot = torch.tensor(fips_encoder.transform(np.array(fips_code).reshape(-1, 1)), dtype=torch.float32).to(device)\n",
    "            output = model(sentinel, fips_onehot)\n",
    "            all_predictions.append(output.cpu().numpy())\n",
    "            all_ground_truth.append(usda.cpu().numpy())\n",
    "        \n",
    "    all_predictions = np.concatenate(all_predictions, axis=0)\n",
    "    all_ground_truth = np.concatenate(all_ground_truth, axis=0)\n",
    "    print(all_predictions[:,0])\n",
    "    print(all_ground_truth[:,0])\n",
    "    print(all_predictions[:,1])\n",
    "    print(all_ground_truth[:,1])\n",
    "    results = {}\n",
    "    for i, metric_name in enumerate([\"Production\", \"Yield\"]):\n",
    "        y_true = torch.from_numpy(all_ground_truth[:, i])\n",
    "        y_pred = torch.from_numpy(all_predictions[:, i])\n",
    "        mae = torch.abs(y_true - y_pred).mean()\n",
    "        mse = ((y_pred - y_true) ** 2).mean()\n",
    "        rmse = torch.sqrt(mse)\n",
    "        mape = (torch.abs(y_true - y_pred) / torch.abs(y_true)).mean() * 100\n",
    "        smape = 100 * (torch.abs(y_true - y_pred) / ((torch.abs(y_true) + torch.abs(y_pred)) / 2)).mean()\n",
    "        max_error = torch.abs(y_true - y_pred).max()\n",
    "        corr = torch.corrcoef(torch.stack((y_pred, y_true)))\n",
    "        metrics = {\n",
    "            'MAE': round(mae.item(), 2),\n",
    "            'MSE': round(mse.item(), 2),\n",
    "            'RMSE': round(rmse.item(), 2),\n",
    "            'MAPE': round(mape.item(), 2),\n",
    "            'SMAPE': round(smape.item(), 2),\n",
    "            'Max Error': round(max_error.item(), 2),\n",
    "            'Correlation Coefficient': round(corr[0, 1].item(), 2)\n",
    "        }\n",
    "        results[metric_name] = metrics\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5297ec6e",
   "metadata": {
    "papermill": {
     "duration": 0.005966,
     "end_time": "2024-10-25T06:08:49.110959",
     "exception": false,
     "start_time": "2024-10-25T06:08:49.104993",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Cotton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cdca9506",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-25T06:08:49.125246Z",
     "iopub.status.busy": "2024-10-25T06:08:49.124496Z",
     "iopub.status.idle": "2024-10-25T06:59:26.598458Z",
     "shell.execute_reply": "2024-10-25T06:59:26.597444Z"
    },
    "papermill": {
     "duration": 3037.584242,
     "end_time": "2024-10-25T06:59:26.701336",
     "exception": false,
     "start_time": "2024-10-25T06:08:49.117094",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training: 72it [03:25,  2.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Train Loss: 3.2629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Training: 72it [03:06,  2.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Train Loss: 0.6955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 Training: 72it [03:06,  2.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Train Loss: 0.6386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 Training: 72it [03:06,  2.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Train Loss: 0.6038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 Training: 72it [03:08,  2.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Train Loss: 0.6652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 Training: 72it [03:06,  2.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Train Loss: 0.7035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 Training: 72it [03:06,  2.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Train Loss: 0.5888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 Training: 72it [03:05,  2.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Train Loss: 0.6187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 Training: 72it [03:05,  2.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Train Loss: 0.5520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 Training: 72it [03:04,  2.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Train Loss: 0.5703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11 Training: 72it [03:04,  2.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 - Train Loss: 0.5423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12 Training: 72it [03:04,  2.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 - Train Loss: 0.6521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13 Training: 72it [03:05,  2.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 - Train Loss: 0.6112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14 Training: 72it [03:05,  2.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 - Train Loss: 0.5901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15 Training: 72it [03:06,  2.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 - Train Loss: 0.7183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16 Training: 72it [03:05,  2.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 - Train Loss: 0.6086\n",
      "Early stopping\n",
      "[10.089026 10.075547 10.302738 10.142555 10.218484 10.172125 10.168705\n",
      " 10.301669 10.17576  10.196869 10.165039 10.240346 10.101841 10.08524\n",
      " 10.244759  9.999657 10.120121 10.012542]\n",
      "[ 9.69892    9.230143  10.9937315 10.154246  10.370361   9.792556\n",
      " 10.122623  10.518673  10.781037  10.4399805 10.868568  10.526749\n",
      " 10.39513   10.721063  11.098924   9.400961  10.003333   8.9733515]\n",
      "[6.534198  6.5275645 6.668336  6.5657845 6.6078224 6.586041  6.569924\n",
      " 6.668332  6.5632615 6.5967817 6.569629  6.6342454 6.5204563 6.5207424\n",
      " 6.614581  6.476229  6.5427217 6.477821 ]\n",
      "[6.6618547 7.075809  7.044905  6.605298  6.851185  6.6515718 6.793466\n",
      " 6.788972  6.7007313 6.7007313 6.6253924 7.0012455 6.980076  6.9966817\n",
      " 7.1147695 6.555357  6.568078  6.809039 ]\n",
      "Cotton\n",
      "{'Production': {'Correlation Coefficient': 0.74,\n",
      "                'MAE': 0.45,\n",
      "                'MAPE': 4.45,\n",
      "                'MSE': 0.29,\n",
      "                'Max Error': 1.04,\n",
      "                'RMSE': 0.54,\n",
      "                'SMAPE': 4.44},\n",
      " 'Yield': {'Correlation Coefficient': 0.29,\n",
      "           'MAE': 0.24,\n",
      "           'MAPE': 3.43,\n",
      "           'MSE': 0.09,\n",
      "           'Max Error': 0.55,\n",
      "           'RMSE': 0.29,\n",
      "           'SMAPE': 3.52}}\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "base_dir = \"/kaggle/input/cropnetv2\"\n",
    "train_config = \"/kaggle/working/train_config.json\"\n",
    "test_config = \"/kaggle/working/test_config.json\"\n",
    "\n",
    "train_sentinel_loader = DataLoader(Sentinel2Imagery(base_dir,train_config),batch_size = 1)\n",
    "train_hrrr_loader = DataLoader(HRRRComputedDataset(base_dir,train_config),batch_size = 1)\n",
    "train_usda_loader = DataLoader(USDACropDataset(base_dir,train_config,crop_type),batch_size = 1)\n",
    "    \n",
    "test_sentinel_loader = DataLoader(Sentinel2Imagery(base_dir,test_config),batch_size = 1)\n",
    "test_hrrr_loader = DataLoader(HRRRComputedDataset(base_dir,test_config),batch_size = 1)\n",
    "test_usda_loader = DataLoader(USDACropDataset(base_dir,test_config,crop_type),batch_size = 1)\n",
    "\n",
    "with open(train_config, 'r') as f:\n",
    "    obj = json.load(f)\n",
    "    fips_codes = sorted(obj[\"FIPS\"])\n",
    "    \n",
    "fips_encoder = OneHotEncoder(sparse_output=False)\n",
    "fips_encoder.fit(np.array(fips).reshape(-1, 1))\n",
    "\n",
    "model = CropYieldModel(len(fips_codes))\n",
    "\n",
    "model = train_model(model, (train_sentinel_loader, train_hrrr_loader, train_usda_loader),\n",
    "                    epochs=20, patience=5, save_path=\"best_model.pth\")\n",
    "\n",
    "results = evaluate_model(model, (test_sentinel_loader, test_hrrr_loader, test_usda_loader))\n",
    "print(crop_type)\n",
    "pprint(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498e30ef",
   "metadata": {
    "papermill": {
     "duration": 0.097227,
     "end_time": "2024-10-25T06:59:26.896672",
     "exception": false,
     "start_time": "2024-10-25T06:59:26.799445",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Soybeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "538d2439",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-25T06:59:27.094567Z",
     "iopub.status.busy": "2024-10-25T06:59:27.094180Z",
     "iopub.status.idle": "2024-10-25T06:59:27.104036Z",
     "shell.execute_reply": "2024-10-25T06:59:27.103317Z"
    },
    "papermill": {
     "duration": 0.111654,
     "end_time": "2024-10-25T06:59:27.105879",
     "exception": false,
     "start_time": "2024-10-25T06:59:26.994225",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train\n",
    "years = list(range(2018,2022))\n",
    "state = \"IL\"\n",
    "state_ansi = \"17\"\n",
    "fips = ['17005', '17007', '17009', '17011', '17015', '17019', '17025', '17027', '17037', \n",
    "        '17045', '17049', '17053', '17055', '17057', '17059', '17063', '17073', '17075', '17077', \n",
    "        '17081', '17089', '17091', '17095', '17101', '17103', '17105', '17113', '17115', '17117', \n",
    "        '17119', '17121', '17129', '17133', '17139', '17141', '17143', '17145', '17153', '17157', \n",
    "        '17163', '17167', '17173', '17177', '17179', '17189', '17193', '17197', '17201', '17203']\n",
    "\n",
    "crop_type = \"Soybeans\"\n",
    "grow_season = [4, 9]  # April to September\n",
    "\n",
    "train_config = make_config(years, state, state_ansi, fips, crop_type, grow_season)\n",
    "with open('train_config.json', 'w') as file:\n",
    "    json.dump(train_config, file)\n",
    "\n",
    "# Test\n",
    "years = [2022]\n",
    "test_config = make_config(years,  state, state_ansi, fips, crop_type, grow_season)\n",
    "with open('test_config.json', 'w') as file:\n",
    "    json.dump(test_config, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5dc71d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-25T06:59:27.304453Z",
     "iopub.status.busy": "2024-10-25T06:59:27.303824Z",
     "iopub.status.idle": "2024-10-25T08:16:43.340033Z",
     "shell.execute_reply": "2024-10-25T08:16:43.339047Z"
    },
    "papermill": {
     "duration": 4636.459471,
     "end_time": "2024-10-25T08:16:43.663821",
     "exception": false,
     "start_time": "2024-10-25T06:59:27.204350",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training: 196it [07:18,  2.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Train Loss: 3.0597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Training: 196it [06:49,  2.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Train Loss: 1.1047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 Training: 196it [06:51,  2.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Train Loss: 1.1253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 Training: 196it [06:52,  2.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Train Loss: 1.1654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 Training: 196it [06:52,  2.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Train Loss: 1.0063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 Training: 196it [06:49,  2.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Train Loss: 0.8809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 Training: 196it [06:43,  2.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Train Loss: 1.0951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 Training: 196it [06:45,  2.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Train Loss: 0.9969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 Training: 196it [06:52,  2.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Train Loss: 0.9595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 Training: 196it [06:53,  2.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Train Loss: 0.9160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11 Training: 196it [06:54,  2.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 - Train Loss: 1.0931\n",
      "Early stopping\n",
      "[14.842931  14.7063465 14.676423  14.815689  14.764834  14.888553\n",
      " 14.684739  14.73956   14.823714  14.830167  14.778219  14.757054\n",
      " 14.706213  14.728454  14.69974   14.738306  14.812417  14.860637\n",
      " 14.746842  14.771118  14.692784  14.784295  14.838031  14.745439\n",
      " 14.762967  14.811901  14.855961  14.69806   14.799323  14.718449\n",
      " 14.716773  14.738996  14.68303   14.76261   14.74095   14.729477\n",
      " 14.682932  14.718153  14.807362  14.741618  14.84672   14.75712\n",
      " 14.750951  14.685553  14.764732  14.714651  14.76456   14.66651\n",
      " 14.75534  ]\n",
      "[15.402089  14.958139  14.715672  16.273218  15.050401  16.715998\n",
      " 15.638446  15.553165  15.956517  16.225693  15.585365  16.006493\n",
      " 15.211013  15.891822  15.290045  15.627236  16.31842   16.762262\n",
      " 15.36009   15.445339  15.150512  15.927903  16.007277  15.468008\n",
      " 16.058239  16.700703  16.86885   16.122486  16.281658  15.761849\n",
      " 15.542731  15.364137  15.346987  15.488862  15.985821  15.533624\n",
      " 15.245583  14.6918125 15.61408   15.621994  16.407402  16.269527\n",
      " 15.519349  15.995589  15.845631  15.788063  15.605435  15.088916\n",
      " 15.871555 ]\n",
      "[3.6335063 3.59704   3.5856607 3.6212173 3.6084352 3.6412714 3.5914443\n",
      " 3.597908  3.625328  3.6211867 3.6108558 3.605375  3.5908797 3.5997672\n",
      " 3.5879598 3.6025715 3.621702  3.636051  3.6051662 3.6091845 3.5866077\n",
      " 3.6149433 3.6267414 3.6033373 3.6087286 3.6230147 3.6359305 3.59152\n",
      " 3.6165433 3.596858  3.597284  3.603373  3.5898986 3.6081967 3.603549\n",
      " 3.6011033 3.58829   3.5982103 3.618987  3.6016803 3.6278398 3.6082177\n",
      " 3.6050181 3.5931954 3.6056879 3.5952642 3.6080523 3.5857785 3.6058435]\n",
      "[4.0707345 4.130355  4.1651134 4.2121277 4.232656  4.2398868 4.0483007\n",
      " 4.000034  4.1728477 4.218036  4.0926766 4.200205  3.8501475 4.1351666\n",
      " 4.012773  4.1447206 4.201703  4.155753  3.9337845 3.8732822 4.1651134\n",
      " 4.089332  4.204693  4.060443  4.201703  4.15104   4.2312036 4.3013587\n",
      " 4.1759243 4.0876555 3.9945242 4.218036  3.9721768 4.1850986 4.213608\n",
      " 4.158883  3.7704594 3.9796817 3.918005  3.981549  4.286341  4.206184\n",
      " 4.1319613 4.26268   3.9219732 3.9982007 4.046554  4.139955  4.2355547]\n",
      "Soybeans\n",
      "{'Production': {'Correlation Coefficient': 0.7,\n",
      "                'MAE': 0.98,\n",
      "                'MAPE': 6.15,\n",
      "                'MSE': 1.18,\n",
      "                'Max Error': 2.01,\n",
      "                'RMSE': 1.09,\n",
      "                'SMAPE': 6.39},\n",
      " 'Yield': {'Correlation Coefficient': 0.35,\n",
      "           'MAE': 0.5,\n",
      "           'MAPE': 12.16,\n",
      "           'MSE': 0.27,\n",
      "           'Max Error': 0.71,\n",
      "           'RMSE': 0.52,\n",
      "           'SMAPE': 12.99}}\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "base_dir = \"/kaggle/input/cropnetv2\"\n",
    "train_config = \"/kaggle/working/train_config.json\"\n",
    "test_config = \"/kaggle/working/test_config.json\"\n",
    "\n",
    "train_sentinel_loader = DataLoader(Sentinel2Imagery(base_dir,train_config),batch_size = 1)\n",
    "train_hrrr_loader = DataLoader(HRRRComputedDataset(base_dir,train_config),batch_size = 1)\n",
    "train_usda_loader = DataLoader(USDACropDataset(base_dir,train_config,crop_type),batch_size = 1)\n",
    "    \n",
    "test_sentinel_loader = DataLoader(Sentinel2Imagery(base_dir,test_config),batch_size = 1)\n",
    "test_hrrr_loader = DataLoader(HRRRComputedDataset(base_dir,test_config),batch_size = 1)\n",
    "test_usda_loader = DataLoader(USDACropDataset(base_dir,test_config,crop_type),batch_size = 1)\n",
    "\n",
    "with open(train_config, 'r') as f:\n",
    "    obj = json.load(f)\n",
    "    fips_codes = sorted(obj[\"FIPS\"])\n",
    "    \n",
    "fips_encoder = OneHotEncoder(sparse_output=False)\n",
    "fips_encoder.fit(np.array(fips).reshape(-1, 1))\n",
    "\n",
    "model = CropYieldModel(len(fips_codes))\n",
    "\n",
    "model = train_model(model, (train_sentinel_loader, train_hrrr_loader, train_usda_loader),\n",
    "                    epochs=20, patience=5, save_path=\"best_model.pth\")\n",
    "\n",
    "results = evaluate_model(model, (test_sentinel_loader, test_hrrr_loader, test_usda_loader))\n",
    "print(crop_type)\n",
    "pprint(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7876217d",
   "metadata": {
    "papermill": {
     "duration": 0.285716,
     "end_time": "2024-10-25T08:16:44.215075",
     "exception": false,
     "start_time": "2024-10-25T08:16:43.929359",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Corn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39e57810",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-25T08:16:44.778290Z",
     "iopub.status.busy": "2024-10-25T08:16:44.777517Z",
     "iopub.status.idle": "2024-10-25T08:16:44.792212Z",
     "shell.execute_reply": "2024-10-25T08:16:44.791398Z"
    },
    "papermill": {
     "duration": 0.304438,
     "end_time": "2024-10-25T08:16:44.794367",
     "exception": false,
     "start_time": "2024-10-25T08:16:44.489929",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train config\n",
      "{'FIPS': ['17007',\n",
      "          '17011',\n",
      "          '17015',\n",
      "          '17017',\n",
      "          '17019',\n",
      "          '17021',\n",
      "          '17025',\n",
      "          '17027',\n",
      "          '17037',\n",
      "          '17049',\n",
      "          '17053',\n",
      "          '17055',\n",
      "          '17057',\n",
      "          '17059',\n",
      "          '17061',\n",
      "          '17063',\n",
      "          '17073',\n",
      "          '17075',\n",
      "          '17077',\n",
      "          '17081',\n",
      "          '17085',\n",
      "          '17089',\n",
      "          '17093',\n",
      "          '17095',\n",
      "          '17101',\n",
      "          '17103',\n",
      "          '17105',\n",
      "          '17107',\n",
      "          '17113',\n",
      "          '17115',\n",
      "          '17117',\n",
      "          '17119',\n",
      "          '17121',\n",
      "          '17123',\n",
      "          '17133',\n",
      "          '17135',\n",
      "          '17139',\n",
      "          '17141',\n",
      "          '17143',\n",
      "          '17147',\n",
      "          '17157',\n",
      "          '17163',\n",
      "          '17167',\n",
      "          '17169',\n",
      "          '17173',\n",
      "          '17175',\n",
      "          '17177',\n",
      "          '17179',\n",
      "          '17189',\n",
      "          '17193',\n",
      "          '17195',\n",
      "          '17201',\n",
      "          '17203'],\n",
      " 'crop_type': 'Corn',\n",
      " 'data': {'HRRR': {'short_term': [['HRRR/2018/IL/HRRR_17_IL_2018-04.csv',\n",
      "                                   'HRRR/2018/IL/HRRR_17_IL_2018-05.csv',\n",
      "                                   'HRRR/2018/IL/HRRR_17_IL_2018-06.csv',\n",
      "                                   'HRRR/2018/IL/HRRR_17_IL_2018-07.csv',\n",
      "                                   'HRRR/2018/IL/HRRR_17_IL_2018-08.csv',\n",
      "                                   'HRRR/2018/IL/HRRR_17_IL_2018-09.csv'],\n",
      "                                  ['HRRR/2019/IL/HRRR_17_IL_2019-04.csv',\n",
      "                                   'HRRR/2019/IL/HRRR_17_IL_2019-05.csv',\n",
      "                                   'HRRR/2019/IL/HRRR_17_IL_2019-06.csv',\n",
      "                                   'HRRR/2019/IL/HRRR_17_IL_2019-07.csv',\n",
      "                                   'HRRR/2019/IL/HRRR_17_IL_2019-08.csv',\n",
      "                                   'HRRR/2019/IL/HRRR_17_IL_2019-09.csv'],\n",
      "                                  ['HRRR/2020/IL/HRRR_17_IL_2020-04.csv',\n",
      "                                   'HRRR/2020/IL/HRRR_17_IL_2020-05.csv',\n",
      "                                   'HRRR/2020/IL/HRRR_17_IL_2020-06.csv',\n",
      "                                   'HRRR/2020/IL/HRRR_17_IL_2020-07.csv',\n",
      "                                   'HRRR/2020/IL/HRRR_17_IL_2020-08.csv',\n",
      "                                   'HRRR/2020/IL/HRRR_17_IL_2020-09.csv'],\n",
      "                                  ['HRRR/2021/IL/HRRR_17_IL_2021-04.csv',\n",
      "                                   'HRRR/2021/IL/HRRR_17_IL_2021-05.csv',\n",
      "                                   'HRRR/2021/IL/HRRR_17_IL_2021-06.csv',\n",
      "                                   'HRRR/2021/IL/HRRR_17_IL_2021-07.csv',\n",
      "                                   'HRRR/2021/IL/HRRR_17_IL_2021-08.csv',\n",
      "                                   'HRRR/2021/IL/HRRR_17_IL_2021-09.csv']]},\n",
      "          'USDA': ['USDA/Corn/2018/USDA_Corn_County_2018.csv',\n",
      "                   'USDA/Corn/2019/USDA_Corn_County_2019.csv',\n",
      "                   'USDA/Corn/2020/USDA_Corn_County_2020.csv',\n",
      "                   'USDA/Corn/2021/USDA_Corn_County_2021.csv'],\n",
      "          'sentinel': [['AG/IL/2018/Agriculture_17_IL_2018-04-01_2018-06-30.h5',\n",
      "                        'AG/IL/2018/Agriculture_17_IL_2018-07-01_2018-09-30.h5'],\n",
      "                       ['AG/IL/2019/Agriculture_17_IL_2019-04-01_2019-06-30.h5',\n",
      "                        'AG/IL/2019/Agriculture_17_IL_2019-07-01_2019-09-30.h5'],\n",
      "                       ['AG/IL/2020/Agriculture_17_IL_2020-04-01_2020-06-30.h5',\n",
      "                        'AG/IL/2020/Agriculture_17_IL_2020-07-01_2020-09-30.h5'],\n",
      "                       ['AG/IL/2021/Agriculture_17_IL_2021-04-01_2021-06-30.h5',\n",
      "                        'AG/IL/2021/Agriculture_17_IL_2021-07-01_2021-09-30.h5']]},\n",
      " 'state': 'IL',\n",
      " 'years': [2018, 2019, 2020, 2021]}\n",
      "Test config\n",
      "{'FIPS': ['17007',\n",
      "          '17011',\n",
      "          '17015',\n",
      "          '17017',\n",
      "          '17019',\n",
      "          '17021',\n",
      "          '17025',\n",
      "          '17027',\n",
      "          '17037',\n",
      "          '17049',\n",
      "          '17053',\n",
      "          '17055',\n",
      "          '17057',\n",
      "          '17059',\n",
      "          '17061',\n",
      "          '17063',\n",
      "          '17073',\n",
      "          '17075',\n",
      "          '17077',\n",
      "          '17081',\n",
      "          '17085',\n",
      "          '17089',\n",
      "          '17093',\n",
      "          '17095',\n",
      "          '17101',\n",
      "          '17103',\n",
      "          '17105',\n",
      "          '17107',\n",
      "          '17113',\n",
      "          '17115',\n",
      "          '17117',\n",
      "          '17119',\n",
      "          '17121',\n",
      "          '17123',\n",
      "          '17133',\n",
      "          '17135',\n",
      "          '17139',\n",
      "          '17141',\n",
      "          '17143',\n",
      "          '17147',\n",
      "          '17157',\n",
      "          '17163',\n",
      "          '17167',\n",
      "          '17169',\n",
      "          '17173',\n",
      "          '17175',\n",
      "          '17177',\n",
      "          '17179',\n",
      "          '17189',\n",
      "          '17193',\n",
      "          '17195',\n",
      "          '17201',\n",
      "          '17203'],\n",
      " 'crop_type': 'Corn',\n",
      " 'data': {'HRRR': {'short_term': [['HRRR/2022/IL/HRRR_17_IL_2022-04.csv',\n",
      "                                   'HRRR/2022/IL/HRRR_17_IL_2022-05.csv',\n",
      "                                   'HRRR/2022/IL/HRRR_17_IL_2022-06.csv',\n",
      "                                   'HRRR/2022/IL/HRRR_17_IL_2022-07.csv',\n",
      "                                   'HRRR/2022/IL/HRRR_17_IL_2022-08.csv',\n",
      "                                   'HRRR/2022/IL/HRRR_17_IL_2022-09.csv']]},\n",
      "          'USDA': ['USDA/Corn/2022/USDA_Corn_County_2022.csv'],\n",
      "          'sentinel': [['AG/IL/2022/Agriculture_17_IL_2022-04-01_2022-06-30.h5',\n",
      "                        'AG/IL/2022/Agriculture_17_IL_2022-07-01_2022-09-30.h5']]},\n",
      " 'state': 'IL',\n",
      " 'years': [2022]}\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "years = list(range(2018,2022))\n",
    "state = \"IL\"\n",
    "state_ansi = \"17\"\n",
    "fips = ['17007', '17011', '17015', '17017', '17019', '17021', '17025', '17027',  \n",
    "        '17037', '17049', '17053', '17055', '17057', '17059', '17061', '17063', '17073', \n",
    "        '17075', '17077', '17081', '17085', '17089', '17093', '17095', '17101', '17103', \n",
    "        '17105', '17107', '17113', '17115', '17117', '17119', '17121', '17123', '17133', \n",
    "        '17135', '17139', '17141', '17143', '17147', '17157', '17163', '17167', '17169', \n",
    "        '17173', '17175', '17177', '17179', '17189', '17193', '17195', '17201', '17203'] \n",
    "crop_type = \"Corn\"\n",
    "grow_season = [4, 9]  # April to September\n",
    "\n",
    "train_config = make_config(years, state, state_ansi, fips, crop_type, grow_season)\n",
    "with open('train_config.json', 'w') as file:\n",
    "    json.dump(train_config, file)\n",
    "print(\"Train config\")\n",
    "pprint(train_config)\n",
    "\n",
    "# Test\n",
    "years = [2022]\n",
    "test_config = make_config(years,  state, state_ansi, fips, crop_type, grow_season)\n",
    "with open('test_config.json', 'w') as file:\n",
    "    json.dump(test_config, file)\n",
    "print(\"Test config\")\n",
    "pprint(test_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb4cc801",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-25T08:16:45.331200Z",
     "iopub.status.busy": "2024-10-25T08:16:45.330824Z",
     "iopub.status.idle": "2024-10-25T10:43:26.844401Z",
     "shell.execute_reply": "2024-10-25T10:43:26.843417Z"
    },
    "papermill": {
     "duration": 8802.376009,
     "end_time": "2024-10-25T10:43:27.437895",
     "exception": false,
     "start_time": "2024-10-25T08:16:45.061886",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training: 212it [07:23,  2.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Train Loss: 2.9330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Training: 212it [07:19,  2.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Train Loss: 1.1144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 Training: 212it [07:19,  2.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Train Loss: 1.0095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 Training: 212it [07:21,  2.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Train Loss: 1.1659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 Training: 212it [07:13,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Train Loss: 0.9457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 Training: 212it [07:08,  2.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Train Loss: 0.9288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 Training: 212it [07:11,  2.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Train Loss: 0.9136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 Training: 212it [07:11,  2.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Train Loss: 0.9239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 Training: 212it [07:12,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Train Loss: 0.8837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 Training: 212it [07:11,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Train Loss: 0.8799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11 Training: 212it [07:09,  2.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 - Train Loss: 0.9284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12 Training: 212it [07:11,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 - Train Loss: 1.0790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13 Training: 212it [07:14,  2.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 - Train Loss: 0.8762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14 Training: 212it [07:13,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 - Train Loss: 0.9224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15 Training: 212it [07:13,  2.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 - Train Loss: 0.8529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16 Training: 212it [07:13,  2.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 - Train Loss: 0.8877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17 Training: 212it [07:17,  2.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 - Train Loss: 0.9017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18 Training: 212it [07:20,  2.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 - Train Loss: 0.8391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19 Training: 212it [07:19,  2.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 - Train Loss: 0.8117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20 Training: 212it [07:21,  2.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 - Train Loss: 0.8153\n",
      "[16.929138 17.28495  17.16301  17.034496 17.196236 17.163212 17.007309\n",
      " 16.934254 17.196064 17.005657 17.045326 16.802578 17.261654 16.922016\n",
      " 17.06503  17.058468 17.219997 17.270031 16.778854 16.755219 17.075283\n",
      " 17.271183 17.136593 17.30402  16.916214 17.27752  17.263279 16.990482\n",
      " 17.305828 17.04565  17.130127 16.8539   16.892147 17.010498 16.737762\n",
      " 17.119053 17.076347 17.288216 17.126019 17.050762 17.058334 17.035717\n",
      " 17.31791  16.803612 17.213993 17.038155 17.18021  17.189415 16.945545\n",
      " 16.877167 17.148407 17.017467 17.001244]\n",
      "[16.461685 17.813234 17.14446  16.6308   17.875126 17.532614 16.464306\n",
      " 16.747557 17.526592 16.709764 17.217207 15.608103 17.13499  16.099014\n",
      " 16.859509 16.810692 17.720045 17.986538 15.473167 15.850085 16.730358\n",
      " 16.503767 16.54127  17.340046 16.363    17.73284  17.939285 17.510695\n",
      " 18.077923 17.29758  17.347853 16.811243 16.517073 16.807787 15.867195\n",
      " 17.310411 16.688057 17.65936  16.922785 17.099276 16.115091 16.610472\n",
      " 17.5927   16.251226 17.413616 16.830015 17.269396 17.26464  16.74809\n",
      " 16.562525 17.633202 16.668873 17.180044]\n",
      "[5.2538853 5.357005  5.320098  5.2857513 5.3309383 5.3211823 5.2761106\n",
      " 5.2544966 5.3312454 5.2754145 5.285984  5.215458  5.348954  5.250595\n",
      " 5.293174  5.2902346 5.335848  5.3513727 5.209876  5.2010803 5.295394\n",
      " 5.3532248 5.314769  5.3621073 5.249648  5.354478  5.3507195 5.271801\n",
      " 5.3616247 5.28473   5.311222  5.231594  5.2407503 5.277111  5.197007\n",
      " 5.3098555 5.2952566 5.357683  5.3117237 5.287511  5.29084   5.2850285\n",
      " 5.3666763 5.2152224 5.3368053 5.2845116 5.3239193 5.329115  5.258396\n",
      " 5.237257  5.317642  5.2788258 5.274419 ]\n",
      "[5.343291  5.416545  5.4302225 5.370173  5.3895283 5.4200926 5.3166485\n",
      " 5.2806625 5.412092  5.39771   5.4049273 5.171052  5.358942  5.207845\n",
      " 5.334649  5.3724966 5.446306  5.3584714 5.164214  5.0900626 5.3509097\n",
      " 5.370638  5.3995194 5.433722  5.258016  5.41343   5.3631682 5.434159\n",
      " 5.4480295 5.44889   5.343291  5.3023095 5.2694035 5.401325  5.1416636\n",
      " 5.365041  5.349486  5.458308  5.4138756 5.394082  5.1451664 5.2219763\n",
      " 5.4437156 5.2847257 5.36831   5.4831357 5.345678  5.4376445 5.219274\n",
      " 5.248076  5.392718  5.3303003 5.4625597]\n",
      "Corn\n",
      "{'Production': {'Correlation Coefficient': 0.82,\n",
      "                'MAE': 0.42,\n",
      "                'MAPE': 2.5,\n",
      "                'MSE': 0.26,\n",
      "                'Max Error': 1.31,\n",
      "                'RMSE': 0.51,\n",
      "                'SMAPE': 2.48},\n",
      " 'Yield': {'Correlation Coefficient': 0.71,\n",
      "           'MAE': 0.07,\n",
      "           'MAPE': 1.38,\n",
      "           'MSE': 0.01,\n",
      "           'Max Error': 0.2,\n",
      "           'RMSE': 0.09,\n",
      "           'SMAPE': 1.39}}\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "base_dir = \"/kaggle/input/cropnetv2\"\n",
    "train_config = \"/kaggle/working/train_config.json\"\n",
    "test_config = \"/kaggle/working/test_config.json\"\n",
    "\n",
    "train_sentinel_loader = DataLoader(Sentinel2Imagery(base_dir,train_config),batch_size = 1)\n",
    "train_hrrr_loader = DataLoader(HRRRComputedDataset(base_dir,train_config),batch_size = 1)\n",
    "train_usda_loader = DataLoader(USDACropDataset(base_dir,train_config,crop_type),batch_size = 1)\n",
    "    \n",
    "test_sentinel_loader = DataLoader(Sentinel2Imagery(base_dir,test_config),batch_size = 1)\n",
    "test_hrrr_loader = DataLoader(HRRRComputedDataset(base_dir,test_config),batch_size = 1)\n",
    "test_usda_loader = DataLoader(USDACropDataset(base_dir,test_config,crop_type),batch_size = 1)\n",
    "\n",
    "with open(train_config, 'r') as f:\n",
    "    obj = json.load(f)\n",
    "    fips_codes = sorted(obj[\"FIPS\"])\n",
    "    \n",
    "fips_encoder = OneHotEncoder(sparse_output=False)\n",
    "fips_encoder.fit(np.array(fips).reshape(-1, 1))\n",
    "\n",
    "model = CropYieldModel(len(fips_codes))\n",
    "\n",
    "model = train_model(model, (train_sentinel_loader, train_hrrr_loader, train_usda_loader),\n",
    "                    epochs=20, patience=5, save_path=\"best_model.pth\")\n",
    "\n",
    "results = evaluate_model(model, (test_sentinel_loader, test_hrrr_loader, test_usda_loader))\n",
    "print(crop_type)\n",
    "pprint(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703ac6bf",
   "metadata": {
    "papermill": {
     "duration": 0.622927,
     "end_time": "2024-10-25T10:43:28.698159",
     "exception": false,
     "start_time": "2024-10-25T10:43:28.075232",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Winter Wheat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1242f88e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-25T10:43:29.921689Z",
     "iopub.status.busy": "2024-10-25T10:43:29.920714Z",
     "iopub.status.idle": "2024-10-25T10:43:29.936075Z",
     "shell.execute_reply": "2024-10-25T10:43:29.935364Z"
    },
    "papermill": {
     "duration": 0.616525,
     "end_time": "2024-10-25T10:43:29.937899",
     "exception": false,
     "start_time": "2024-10-25T10:43:29.321374",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_config(years: List[int], state: str, state_ansi: str, fips: str, crop_type: str, grow_season: List[int]):\n",
    "    \"\"\"\n",
    "    Creates configuration for winter wheat data collection\n",
    "    grow_season: List containing [start_month, end_month] of the growing cycle\n",
    "                 For winter wheat, this spans across year boundary\n",
    "    \"\"\"\n",
    "    config = {\n",
    "        \"FIPS\": fips,\n",
    "        \"years\": years,\n",
    "        \"state\": state.upper(),\n",
    "        \"crop_type\": crop_type,\n",
    "        \"data\": {\n",
    "            \"HRRR\": {\n",
    "                \"short_term\": []\n",
    "            },\n",
    "            \"USDA\": [],\n",
    "            \"sentinel\": []\n",
    "        }\n",
    "    }\n",
    "   \n",
    "    for year in years:\n",
    "        # HRRR data - need to consider months from previous year's fall\n",
    "        hrrr_files = []\n",
    "        # Previous year's fall months (planting)\n",
    "        for month in range(9, 13):  # September to December\n",
    "            hrrr_files.append(f\"HRRR/{year-1}/{state.upper()}/HRRR_{state_ansi}_{state.upper()}_{year-1}-{month:02d}.csv\")\n",
    "        # Current year's winter and spring months (growing and harvest)\n",
    "        for month in range(1, 7):  # January to July\n",
    "            hrrr_files.append(f\"HRRR/{year}/{state.upper()}/HRRR_{state_ansi}_{state.upper()}_{year}-{month:02d}.csv\")\n",
    "        \n",
    "        config[\"data\"][\"HRRR\"][\"short_term\"].append(hrrr_files)\n",
    "       \n",
    "        # USDA data\n",
    "        config[\"data\"][\"USDA\"].append(f\"USDA/{crop_type}/{year}/USDA_WinterWheat_County_{year}.csv\")\n",
    "       \n",
    "        # Sentinel data - need to cover previous fall to current summer\n",
    "        quarters = [\n",
    "            # Previous year quarters\n",
    "            (f\"{year-1}-10-01\", f\"{year-1}-12-31\"),  # Q4 (planting)\n",
    "            # Current year quarters\n",
    "            (f\"{year}-01-01\", f\"{year}-03-31\"),      # Q1 (winter growth)\n",
    "            (f\"{year}-04-01\", f\"{year}-06-30\"),      # Q2 (spring growth)\n",
    "        ]\n",
    "       \n",
    "        sentinel_files = []\n",
    "        for start, end in quarters:\n",
    "            sentinel_files.append(f\"AG/{state.upper()}/{start[:4]}/Agriculture_{state_ansi}_{state.upper()}_{start}_{end}.h5\")\n",
    "       \n",
    "        config[\"data\"][\"sentinel\"].append(sentinel_files)\n",
    "   \n",
    "    return config\n",
    "\n",
    "# Train\n",
    "years = list(range(2018, 2022))\n",
    "state = \"IL\"\n",
    "state_ansi = \"17\"\n",
    "fips = ['17011', '17013', '17023', '17025', '17027', '17037', '17047', '17049', '17067', \n",
    "        '17083', '17089', '17095', '17119', '17121', '17125', '17133', '17141', '17157', '17159', \n",
    "        '17163', '17173', '17177', '17179', '17189', '17201'] \n",
    "crop_type = \"WinterWheat\"\n",
    "grow_season = [9, 6]  # September to July (spanning across years)\n",
    "\n",
    "train_config = make_config(years, state, state_ansi, fips, crop_type, grow_season)\n",
    "with open('train_config.json', 'w') as file:\n",
    "    json.dump(train_config, file)\n",
    "\n",
    "\n",
    "# Test\n",
    "years = [2022]\n",
    "test_config = make_config(years, state, state_ansi, fips, crop_type, grow_season)\n",
    "with open('test_config.json', 'w') as file:\n",
    "    json.dump(test_config, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bba15a6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-25T10:43:31.182489Z",
     "iopub.status.busy": "2024-10-25T10:43:31.181804Z",
     "iopub.status.idle": "2024-10-25T12:05:57.340459Z",
     "shell.execute_reply": "2024-10-25T12:05:57.339457Z"
    },
    "papermill": {
     "duration": 4947.467945,
     "end_time": "2024-10-25T12:05:58.058270",
     "exception": false,
     "start_time": "2024-10-25T10:43:30.590325",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training: 100it [05:44,  3.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Train Loss: 4.2915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Training: 100it [05:25,  3.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Train Loss: 1.1492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 Training: 100it [05:26,  3.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Train Loss: 0.9965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 Training: 100it [05:31,  3.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Train Loss: 1.0789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 Training: 100it [05:26,  3.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Train Loss: 1.0096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 Training: 100it [05:21,  3.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Train Loss: 1.1407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 Training: 100it [05:20,  3.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Train Loss: 0.9762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 Training: 100it [05:20,  3.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Train Loss: 0.8659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 Training: 100it [05:22,  3.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Train Loss: 0.9317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 Training: 100it [05:22,  3.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Train Loss: 0.7978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11 Training: 100it [05:21,  3.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 - Train Loss: 0.9127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12 Training: 100it [05:21,  3.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 - Train Loss: 0.8809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13 Training: 100it [05:21,  3.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 - Train Loss: 0.8326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14 Training: 100it [05:21,  3.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 - Train Loss: 0.9601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15 Training: 100it [05:22,  3.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 - Train Loss: 0.8291\n",
      "Early stopping\n",
      "[12.065768  12.002904  12.070011  12.105804  12.138816  12.039427\n",
      " 12.078158  12.10844   12.052681  12.0421295 11.947662  11.972492\n",
      " 12.207968  12.187806  12.031501  12.139296  12.073464  12.183838\n",
      " 12.111438  12.136925  11.985008  11.930388  12.035559  12.192896\n",
      " 11.991358 ]\n",
      "[11.91839   12.106253  12.628067  14.008607  14.616166  12.966879\n",
      " 12.694653  13.144125  11.877568  12.524527  12.264341  10.687389\n",
      " 13.946539  13.949167  11.827736  14.346726  12.863593  14.757859\n",
      " 13.3984785 14.402185  13.153862  12.396693  12.621488  15.340044\n",
      " 12.464583 ]\n",
      "[3.984835  3.945261  3.9563148 3.9726503 3.9818919 3.9652646 3.9719622\n",
      " 3.9916441 3.973873  3.9607239 3.9291275 3.932956  4.012988  4.0066986\n",
      " 3.9450736 3.9808257 3.9784133 4.0085807 3.9848819 3.9863217 3.9298685\n",
      " 3.9145608 3.9545815 3.9867175 3.9343486]\n",
      "[4.572647  4.352855  4.5325994 4.447346  4.3907385 4.2904596 4.2668962\n",
      " 4.3605475 4.377014  4.355426  4.506454  4.433195  4.3579903 4.4236484\n",
      " 4.1972017 4.252772  4.5819016 4.3719764 4.38577   4.4308167 4.365643\n",
      " 4.506454  4.5042443 4.4391155 4.3969154]\n",
      "WinterWheat\n",
      "{'Production': {'Correlation Coefficient': 0.8,\n",
      "                'MAE': 1.15,\n",
      "                'MAPE': 8.38,\n",
      "                'MSE': 2.06,\n",
      "                'Max Error': 3.15,\n",
      "                'RMSE': 1.44,\n",
      "                'SMAPE': 8.88},\n",
      " 'Yield': {'Correlation Coefficient': -0.09,\n",
      "           'MAE': 0.44,\n",
      "           'MAPE': 9.87,\n",
      "           'MSE': 0.2,\n",
      "           'Max Error': 0.6,\n",
      "           'RMSE': 0.45,\n",
      "           'SMAPE': 10.4}}\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "base_dir = \"/kaggle/input/cropnetv2\"\n",
    "train_config = \"/kaggle/working/train_config.json\"\n",
    "test_config = \"/kaggle/working/test_config.json\"\n",
    "\n",
    "train_sentinel_loader = DataLoader(Sentinel2Imagery(base_dir,train_config),batch_size = 1)\n",
    "train_hrrr_loader = DataLoader(HRRRComputedDataset(base_dir,train_config),batch_size = 1)\n",
    "train_usda_loader = DataLoader(USDACropDataset(base_dir,train_config,crop_type),batch_size = 1)\n",
    "    \n",
    "test_sentinel_loader = DataLoader(Sentinel2Imagery(base_dir,test_config),batch_size = 1)\n",
    "test_hrrr_loader = DataLoader(HRRRComputedDataset(base_dir,test_config),batch_size = 1)\n",
    "test_usda_loader = DataLoader(USDACropDataset(base_dir,test_config,crop_type),batch_size = 1)\n",
    "\n",
    "with open(train_config, 'r') as f:\n",
    "    obj = json.load(f)\n",
    "    fips_codes = sorted(obj[\"FIPS\"])\n",
    "    \n",
    "fips_encoder = OneHotEncoder(sparse_output=False)\n",
    "fips_encoder.fit(np.array(fips).reshape(-1, 1))\n",
    "\n",
    "model = CropYieldModel(len(fips_codes))\n",
    "\n",
    "model = train_model(model, (train_sentinel_loader, train_hrrr_loader, train_usda_loader),\n",
    "                    epochs=20, patience=5, save_path=\"best_model.pth\")\n",
    "\n",
    "results = evaluate_model(model, (test_sentinel_loader, test_hrrr_loader, test_usda_loader))\n",
    "print(crop_type)\n",
    "pprint(results)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5852641,
     "sourceId": 9594770,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 21454.721598,
   "end_time": "2024-10-25T12:06:00.440792",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-10-25T06:08:25.719194",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
